\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[colorlinks]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\graphicspath{ {images/} }

\author{Daniel Monjas Miguélez}

\title{Apuntes de Arquitectura de Sistemas}

\begin{document}
\maketitle

\newpage

\tableofcontents

\newpage

\section{Tema 1: Soporte Hardware}
\subsection{Motivación}
\begin{figure}[h]
\centering
\includegraphics[scale=0.8,width=\textwidth]{gestion_memoria.png}
\end{figure}
\newpage

Para una matriz de tamaño $10000\times 10000$:
\begin{figure}[h]
\centering
\includegraphics[scale=0.8,width=\textwidth]{time.png}
\end{figure}

La causa de este fenómeno es la forma en que C gestiona la memoria, pues C/C++ almacenan las matrices por filas. Ejemplo: $int\:\:m[4][4]$
\begin{figure}[h]
\centering
\includegraphics[scale=0.6,width=80mm]{ejemplo4x4.png}
\end{figure}

\textbf{Memoria Virtual}

Es una utilidad que permite a los programas direccionar la memoria desde un punto de vista lógico, sin importar la cantidad de memoria principal física disponible. Se concebió como método para tener múltiples trabajos de usuario residiendo en memoria principal de forma concurrente, de forma que no exista un intervalo de tiempo de espera entre la ejecución de procesos sucesivos, es decir, mientras un proceso se escribe en almacenamiento secundario y se lee el sucesor. Se introdujeron los sistemas de paginación, que permiten que los procesos se compriman en un número determinado de bloques de tamaño fijo, denominados páginas. Un programa referencia a una palabra por medio de una dirección virtual, que consiste en un número de página y un desplazamiento dentro de la página.

Todas las páginas de un proceso se mantienen en disco. Cuando un proceso está en ejecución, algunas de sus páginas se encuentran en memoria principal, y si se referencia a una página que no está en memoria principal el hardware de gestión de memoria lo detecta y permite que la página que falta se cargue (carga bajo demanda).

\subsection{Clasificación}
\subsubsection{Clasificación "práctica" de arquitecturas paralelas}
\begin{itemize}
\item Multiprocesadores de memoria compartida:
	\begin{itemize}
	\item SMT(Simultaneos Multithreading/Hyperthreading): permite a una única CPU ejecutar varios flujos de control. Esto requiere tener múltiples copias de algunos componentes hardware de la CPU, como contadores de programa y registros de archivo, mientras otras partes siguen siendo únicas como las unidades que realizan aritmética con punto flotante. Cuando un procesador tiene Hyper-Threading puede tener de 2 a 64 hebras (puede tener más, veanse procesadores de servidor), dependiendo del número de núcleos físicos del mismo.
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=\textwidth]{Hyperthreading.jpg}
	\end{figure}
	
	\item SMP(Symmetric Multi-Processing): el núcleo puede ejecutar en cualquier procesador, y normalmente cada procesador realiza su propia planificación del conjunto disponible de procesos e hilos. El núcleo puede construirse como múltiples procesos o múltiples hilos, permitiéndose la ejecución de partes del núcleo en paralelo. El enfoque SMP complica el sistema operativo, ya que debe asegurar que dos procesadores no seleccionan un mismo proceso y que no se pierde ningún proceso de la cola. Se deben emplear técnicas para resolver y sincronizar el uso de los recursos. Suelen tener entre 2 y 256 procesadores.
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=\textwidth]{SMP.png}
	\end{figure}
	
	\item UMA/ccNUMA (Uniforma Memory Access/Cache Coherent  UMA): Se define como la situación en la cual el acceso a cualquier RAM desde CPU toma siempre la misma cantidad de tiempo. Suele tener entre 2 y 4096 procesadores.
	
	\end{itemize}
	
\item Multiprocesadores masivamente paralelos:
	\begin{itemize}
	
	\item NUMA/ccNUMA (Non Uniform Memory Access/ Cache Coherent NUMA): A diferencia de UMA, algunas partes de la memoria pueden tomar más tiempo de acceso que otras, creando una penalización en el rendimiento. Esta penalización se puede minimizar por medio de la administración de recursos.
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=65mm]{umanuma.png}
	\end{figure}
	
	\item Paso de mensajes/NoRMA (No Remote Memory Access): en las arquitecturas NoRMA, el espacio de direcciones global no es único y la memoria no es globalmente accesible desde todos los procesadores. El acceso a modulos de memoria remotos es solo posible indirectamente a través del paso de mensajes por medio de la red de interconexión a otros procesadores, lo que en respuesta recibirá los datos buscados en un mensaje de respuesta.
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=80mm]{NORMA.jpg}
	\end{figure}
	\end{itemize}
	
\item Cluster$\rightarrow$+10M procesadores. Al igual que los sistemas multiprocesadores, los sistemas clústes juntan múltiples CPUs para conseguir un trabajo computacional. La diferencia respecto a los sistemas multiprocesadores en que los clústers se componen de dos o más sistemas individuales unidos juntos, a los que se denominan nodos.
	\begin{itemize}
	\item GPUs
	\end{itemize}
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=70mm]{cluster.png}
	\end{figure}
\end{itemize}

\subsubsection{Clasificación Arquitectura de Computadores}
\begin{itemize}
\item Sistemas monoprocesador
	\begin{itemize}
	\item Bus único
	\item Buses separados/especializados
	\end{itemize}
\item Sistemas multiprocesador
	\begin{itemize}
	\item Multiproceso simétrico (SMP)
	\item Multihebra simultánea (SMT)
	\item Multinúcleo (SMP)
	\end{itemize}
	
\item Sistemas distribuidos
\end{itemize}

\textbf{Sistema monoprocesador:} Es el modelo más simple, pues conecta todo en un bus común.
\begin{itemize}
\item Ventaja$\rightarrow$ precio.
\item Inconveniente $\rightarrow$ infrautilización de componentes por la diferencia de velocidad.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=70mm]{monoprocesador.png}
\end{figure}

Una posible solución para la diferencia de velocidad es aislar los componentes por velocidad y conectarlos por medio de un puente

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=50mm]{solucionmonoprocesador.png}
\end{figure}
\newpage
Otra posible solución incluso mejor es separar el bus de E/S en dos buses en función de los dispositivos E/S más rápidos y más lentos, y conectar ambos buses por medio de un puente isa.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{sol2monoprocesador.png}
\end{figure}

\textbf{Sistema multiprocesador: multiproceso simétrico}. Lo más simple es conectar todos los elementos a un bus común.
\begin{itemize}
\item Ventaja $\rightarrow$ precio.

\item Inconveniente $\rightarrow$ se agrava la infrautilización de componentes.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{multiprocesador.png}
\end{figure}

\newpage

\textbf{Sistemas multiprocesador: multihebra simultánea}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{multiprocesador-multihebra.png}
\end{figure}

\textbf{Sistemas multiprocesador: multiproceso simétrico}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{multiprocesador-multihebra2.png}
\end{figure}

\newpage

\textbf{Sistemas multiprocesador actuales}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=140mm]{multiprocesador_actual.png}
\end{figure}

\textbf{Arquitecturas de un sistema actual}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{arquitectura_actual.png}
\end{figure}

\subsubsection{Componentes}
\textbf{Componentes básicos}
\begin{itemize}
\item Procesadores
\item Jerarquía de memoria.

Surge el problema de que cuanto menor es el tiempo de acceso mayor es el coste por bit, y que cuanto mayor es la capacidad menor la velocidad de acceso. Para lidiar con este dilema surge la jerarquía de memoria. En la jerarquía de memoria según se desciende disminuye el coste por bit, aumenta la capacidad, aumenta el tiempo de acceso y se reduce la frecuencia de acceso a ese nivel de la jerarquí por parte del procesador.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{jerarquiamemoria.png}
\end{figure}


\item Buses de interconexión: AGP, Hypertransport, IDE, IEEE 1394, ISA, M.2, PCI, PCIe, SATA, SCSI, USB, ...
\item Entrada/Salida: controladores, canales de DMA, procesadores de E/S,...
\item Periféricos: altavoz, disco, impresora, micrófono, monitor, ratón, teclado, ...
\end{itemize}

\subsubsection{Procesador}
\textbf{Interfaz del procesador}
\begin{itemize}
\item Conjunto de instrucciones
	\begin{itemize}
	\item transferencia: \begin{verbatim}
	in, mov, out,...
	\end{verbatim}
	
	\item modificación: \begin{verbatim}
	add, and, div, mul, or, sub,...
	\end{verbatim}
	
	\item control: \begin{verbatim}
	cli, sti,...
	\end{verbatim}
	
	\href{http://jegerlehner.ch/intel/IntelCodeTable_es.pdf}{Chuleta instrucciones 8086}
	\end{itemize}

\item Registros generales y especiales

\item Al menos dos modos de ejecución con diferentes privilegios:
	\begin{itemize}
	\item privilegiado: acceso completo
	\item no privilegiado: acceso limitado $\Rightarrow$ excepción
	\end{itemize}
	
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{privilegios.png}
\end{figure}
\end{itemize}

\href{https://upload.wikimedia.org/wikipedia/commons/4/41/Table_of_x86_Registers.png}{Registros del procesador: familia x86-64} \\

En el modo núcleo (modo privilegiado, modo kernel, ...) se pueden ejecutar instrucciones privilegiadas y se puede accesder a áreas de memoria protegidas. Sóla mente el núcleo o kernel del sistema operativo puede ejecutar instrucciones en modo privilegiado. Algunos ejemplos de instrucciones privilegiadas son:

\begin{itemize}
\item Acceso a los dispositivos de E/S: consultar el estado de los dispositivos de E/S, llevar a cabo DMA (Direct Memory Access), atrapar interrupciones.

\item Manipular la unidad de gestión de memoria (MMU): manipualar las tablas de segmento y páginas, cargar y vaciar el búfer de traducción anticipada (TLB)

\item Configurar varios modos de funcionamiento: nivel de prioridad de interrupciones, alterar el vector de interrupción.

\item Utilizar la instrucción $halt$ para activar el modo de ahorro de energía. Esta instrucción detiene abruptamente la CPU hasta que la siguiente interrupción externa ha sido tratada. También es común que se ejecute cuando no hay trabajo inmediato que ejecutar, de forma que se pone al procesador en un estado ocioso.
\end{itemize}

El procesador comprueba el nivel de privilegio en la ejecución de cada instrucción. Los posibles cambios de privilegio son:

\begin{itemize}
\item Usuario $\Rightarrow$ Núcleo: ganar privilegios
	\begin{itemize}
	\item Al arrancar.
	\item Llamada al sistema.
	\item Interrupción hardware.
	\item Excepción.
	\end{itemize}
	
\item Núcleo $\Rightarrow$ Usuario: perder privilegios
	\begin{itemize}
	\item El sistema operativo prepara el entorno necesario para que la aplicación comience su ejecución.
	
	\item El sistema operativo termina alguna de sus actividades y devuelve el control a la aplicación.
	\end{itemize}
\end{itemize}

\textbf{Ciclo de instrucción:} se denomina ciclo de instrucción al procesamiento requerido por una única instrucción. El ciclo de instrucción básco es:

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{ciclo_instruccion.png}
\end{figure}

\begin{itemize}
\item El procesador capta una instrucción desde memoria.

\item La instrucción debe ser decodificada para averiguar su tipo.

\item Conocido el tipo puede ser necesario la captación de nuevos operandos.

\item Se ejecuta la instrucción.

\item Se almacenan los resultados de la ejecución.

\item El proceso se repite instrucción a instrucción hasta que el programa termina.
\end{itemize}

\textbf{Tendencias en el diseño de procesadores}
\begin{itemize}
\item CISC (Complex Instruction Set Computing)$\Rightarrow$ RISC (Reduced Instruction Set Computing) $\Rightarrow$ VLIW (Very Long Instruction Word).

\textbf{CISC}: Es un tipo de diseño de microprocesador. Este contiene un conjunto de instrucciones muy grande que van desde instrucciones muy simples a instrucciones muy especializadas. Se introducen instrucciones que en un diseño RISC se requieren de varias instrucciones, reduciendo así el número de instrucciones de los programas, pero al ser instrucciones más complejas acaban requiriendo más ciclos de reloj para su ejecución.\\

\textbf{RISC}: Como su nombre dice se trata de un diseño de microprocesador. Este diseño contiene instrucciones muy simples y con la combinación de ellas se puede obtener cualquier programa. Si bien su ejecución es rápida, pues son instrucciones muy simples, su tamaño en memoria puede llegar a ser muy grande, pues la ejecución de un programa simple puede requerir de muchas instrucciones RISC.

\textbf{VLIW}: se trata de un procesador segmentado que puede terminar más de una operación por ciclo en el que el compilador es el principal responsable de agrupar operaciones que pueden procesarse en paralelo para definir instrucciones que, de esta forma, se codifican a través de las denominadas palabras de instrucción larga (LIW) o muy larga (VLIW)

\item Ejecución concurrente sobre procesadores: intento de explotación del paralelismo entre instrucciones (ILP). ILP es una mediad de cuántas operaciones pueden ejecutarse simultáneamente sin afectar al resultado.
\end{itemize}

\textbf{Técnicas de explotación de ILP}
\begin{itemize}
\item \textbf{Segmentación de cauce:} la ejecución de múltiples instrucciones puede solaparse total o parcialmente. 

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{segmentacion.png}
\end{figure}

\item \textbf{Ejecución superescalar:} múltiples unidades de ejecución se utilizan para ejecutar múltiples instrucciones en paralelo. Un procesador superescalar es un procesador segmentado que puede finalizar más de una instrucción por ciclo y que posee recursos hardware para extraer el paralelismo entre instrucciones. Para aprovechar al máximo el procesamiento de instrucciones en paralelo que proporcionan las distintas estapas, el procesador incluye una serie de elementos como ventanas de instruccioens o estaciones de buffers, buffers de renombramiento, buffers de reordenamiento, etc.

\item \textbf{Computación con instrucciones explícitamente paralelas (EPIC):} uso del compilador en lugar de complejos circuitos para identificar y explotar el ILP. La intención era permiter un escalado simple del rendimiento sin disparar las frecuencias del reloj. Tiene su base en VLIW.

\item \textbf{Ejecución fuera de orden:} ejecución de instrucciones en cualquier orden que no viole las dependencias entre instrucciones. El orden de ejecución depende de la disponibilidad de los datos de entrada y las unidades de ejecución, no del orden original del programa.

\item \textbf{Renombrado de registros:} técnica para evitar la innecesaria serialización de instrucciones por la reutilización de registros. Puede ser aplicado por el propio compilador al asignar los registros de la arquitectura, pero también puede implementarse en hardware. Esto es lo usual en procesadores superescalares, donde se incluyen estructuras de buffers con una serie de campos específicos (por ejemplo, buffers de renombramiento).

\item \textbf{Ejecución especulativa:} permitir la ejecución de instrucciones completas, o partes, antes de conocer con seguridad si su ejecución debe tener lugar. De esta forma se previene el retraso que habría, de tener que hacer el procesamiento después de saber que es necesario. Si resulta que el procesamiento no era necesario, los cambios realizados se revierten y los resultados se ignoran.

\item \textbf{Predicción de salto:} se utiliza para evitar quedar parado antes de que se resuelvan las dependencias de control. Se utiliza en conjuntción con la ejecución especulativa. Se basa en determinar la alternativa más probable, y continuar el procesamiento, tras las instrucción de salto, con la secuencia de instrucciones que corresponde a dicha opción más probable. Cuando la condición de salto se evalúa, se comprueba si la predicción que se había hecho era correcta o no. Si no lo era habrá que retomar el procesamiento a partir de la primera instrucción de la alternativa que no se tomó, es decir, de la menos probable.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{predicionsalto.png}
\end{figure}

\item \textbf{Multihebra simultánea (SMT):} técnica que permite la ejecución de múltiples hebras de ejecución para aprovechar mejor las unidades funcionales de los procesadores superescalares.
\end{itemize}

\subsubsection{Memoria}

\textbf{Jerarquía de memoria:} Se requiere de jerarquía de memoria entre otras cosas por la gran diferencia de velocidad entre procesador y memoria. La jerarquía de memoria puede aliviar este problema gracias a \textbf{los principios de localidad} y a la \textbf{regla 90/10}:
\begin{itemize}
\item Localidad \textbf{espacial:} la información a la que se accede suelen estar próxima a la que ha sido accedida con anterioridad.

\item Localidad \textbf{temporal:} la información a la que se accede una vez suele volver a ser utilizada.

\item Regla 90/10: el 10\% del código realiza el 90\% del trabajo.
\end{itemize}

\textbf{Tipos de memoria RAM}:
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{tiposram.png}
\end{figure}
\begin{itemize}
\item SRAM (Statica random-access memory): Es un tipo de memoria que utiliza circuitería flip-flop para almacenar cada bit. La diferencia con una DRAM es que la segunda debe de refrescarse periódicamente. La SRAM es más rápida y más cara que la DRAM. Se utiliza típicamente para la caché y los registros internos de la CPU mientras que la DRAM se utiliza para la memoria principal.

\item DDR SDRAM I (Double Data Rate Synchronous RAM): Entre otras cosas las memorias DDR como su nombre indica tienen dos ciclos de reloj, es decir se hace un envío de información cuando el reloj sube y otro cuando el reloj baja. Con esto hace que una memoria DDR con una frecuencia de reloj x duplique el ancho de banda de una SDR SDRAM con igual frecuencia de reloj. Este tipo de memoria se ha visto superada por las versiones 2, 3, 4 y 5 de la misma. Ninguno de sus sucesores tienen compatibilidad ni con su predecesor ni con su sucesor, lo que quiere decir que una RAM DDR1 SDRAM no es compatible con DDR2, DDR3, .... 
\item DDRAM II
\end{itemize}

\textbf{Cantidad de memoria en registros}
\begin{itemize}
\item Tipos de registros:

\item RISC:
	\begin{itemize}
	\item 32 de propósito general (32 ó 64 bits)
	\item 32 de punto flotante (64 bits IEEE 754)
	\item multimedia (64,...,256 bits)
	\end{itemize}

\item CISC: 
	\begin{itemize}
	\item IA32: 8 de propósito general, 8 de punto flotante, 8 multimeida.
	\item IA64: 128 de propósito general, 128 de punto flotante.
	\end{itemize}

\item Algunos procesadores tienen varios conjuntos de estos registros (ventanas de registros)
\end{itemize}

\textbf{Análisis de una jerarquía de dos niveles}
\begin{equation*}
\overline{T}_{acceso}=(1-T_{fallos})\times T_{cache}+T_{fallos}\times(T_{cache}+T_{ram})
\end{equation*}

\textbf{Parámetros de diseño de memorias caché}
\begin{itemize}
\item Tamaño:
	\begin{itemize}
	\item L1:8,...,256KB
	\item L2:1,...,16MB
	\item L3:4,...,128MB
	\end{itemize}
	
\item Tamaño de bloque: 32,...,128B

\item Tiempo de acceso: 1,...,10ns

\item Política de búsqueda:
	\begin{itemize}
	\item bajo demanda
	\item anticipativas
	\end{itemize}

\item Política de colocación:
	\begin{itemize}
	\item correspondencia directa: el bloque $B_j$ de memoria principal se puede ubicar sólo en el marco de bloque que cumple la siguiente relación $i=j\mod{m}$, donde $m$ es el número total de líneas que tiene la cache.
	
	\item asociativa por conjuntos: En la corresponcencia asociativa por conjuntos las líneas de memoria caché se agrupan en $v=2^d$ conjunto con $k$ líneas/conjuto o vías. Se cumple que el número total de marcos de bloque que tiene la caché $m=v*k$. Un bloque $B_j$ de memoria principal se puede ubicar sólo en el conjunto $C_i$ de memoria caché que cumple la siguiente relación $i=j\mod{v}$.
	
	\item completamente asociativa: la caché se organiza en un único conjunto de caché con varias líneas de caché. Un bloque de memoria puede ocupar cualquiera de las lineas de caché. La organización de la caché se puede enmarcar como una matriz de filas (1*m).
	\end{itemize}
	
\item Política de reemplazo:
	\begin{itemize}
	\item LRU
	\item FIFO
	\item aleatoria
	\end{itemize}

\item Política de actualización:
	\begin{itemize}
	\item escritura directa
	\item post-escritura
	\end{itemize}

\item Otras características importantes:
	\begin{itemize}
	\item caché de víctimas
	\item inclusiva/exclusiva
	\item unificada/separada
	\end{itemize}
\end{itemize}

\textbf{Políticas de colocación: correspondencia directa}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=85mm]{correspondenciadirecta.png}
\end{figure}
\newpage

\textbf{Políticas de colocación: correspondencia totalmente asociativa}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=85mm]{totalmenteasociativa.png}
\end{figure}

\newpage

\textbf{Políticas de colocación: correspondencia asociativa por conjuntos (2 M/C)}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=85mm]{porconjuntos.png}
\end{figure}

\textbf{Protección de memoria.}

El sistema operativo debe proteger a los programas entre sí y a él mismo de programas maliciosos o erróneos. Este problema se soluciona utilizando los llamados espacios de direcciones (AS, Address Space). El espacio de direcciones de un computador corresponde al rango de direcciones disponible para un programa de computador.

El procesador dispone de recursos para establecer límites al espacio de direcciones de memoria accesibles por los programas: memoria virtual.

\begin{figure}
\centering
\includegraphics[scale=1,width=\textwidth]{memvirtual.png}
\end{figure}
\newpage

Hay varias implementaciones:

\begin{itemize}
\item Segmentaciones: tamaño variable y arbitrario.
	\begin{itemize}
	\item registro base: principio del espacio de direcciones.
	\item registro límite: tamaño del espacio de direcciones.
	\end{itemize}

\item Paginación: tamaño variable en múltiplos de página.
	\begin{itemize}
	\item tablas de páginas: lista de páginas de un proceso.
	\end{itemize}
\end{itemize} 

La mayoría de los SO asocian un espacio de direcciones diferente para cada proceso (salvo SASOS, Single Adrress Space Operating System):
\begin{itemize}
\item Ventaja $\Rightarrow$ protección automática.

\item Inconveniente $\Rightarrow$ dificulta la compartición
\end{itemize}

Las partes de un espacio de direcciones pueden colocarse en cualquier parte de la memoria física. Algunos espacios de direcciones deben ocupar lugares específicos de la memoria física, ej: dispositivos de E/S.

El procesador debe tener una unidad de gestión de memoria (MMU, Memory Management Unit) extremadamente eficiente porque la traducción entre direcciones virtual-física puede realizarse más de una vez por instrucción. Se requiere una traducción por cada acceso a memoria.\\

\textbf{Traducción de dirección virutal a dirección física}
\begin{enumerate}
\item La ejecución de una instrucción puede requerir varias traducciones, por ejemplo:
	\begin{itemize}
	\item Captacińo de la instrucción.
	
	\item Captación del dato.
	
	\item Escritura del resultado.
	\end{itemize}
	
\item Cada traducción puede requerir varios accesos a memoria:
	\begin{itemize}
	\item Segmentación + paginación.
	
	\item Tablas de página multinivel.
	\end{itemize}
	
\item Se necesita una tabla de traducción por cada espacio de direcciones.

\item Dependerá del tamaño de las direcciones virtuales y físicas, pero habrán al menos tantas entradas como páginas tenga el proceso.
\end{enumerate}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{traduccion.png}
\end{figure}
\newpage

\textbf{Fucnionamiento de la segmentación (x86)}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{segmentacionx86.png}
\end{figure}
\newpage

\textbf{Segmentación + paginación (x86\_64)}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{segmentacionpaginacion.png}
\end{figure}

\textbf{Tabla de páginas multinivel (x86\_64)}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=85mm]{tabla_multinivel.png}
\end{figure}

\newpage

\textbf{Estructura habitual tabla de páginas}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{estructuratabla.png}
\end{figure}

\textbf{Buffer de traducción anticipada (TLB)}

Traducir direcciones por software es muy lento, mientras que mediante hardware puede hacerse más rápido y además podemos añadir una caché de traducciones (TLB). En principio, toda referencia a la memoria virtual puede causar dos accesos a memoria física, uno para buscar la entrada en la tabla de página apropiada y otra para buscar los datos solicitados. De esa forma, el esquema de memoria virtual básico causaría el efecto de duplicar el tiempo de acceso a la memoria. Para solventar este problema, la mayoría de esquemas de la memoria virtual utilizan una \textit{cache} especial de alta velocidad para las entradas de la tabla de páginas, habitualmente denominada buffer de traducción anticipada. TLB:
\begin{itemize}
\item Conenido: pares de direcciones virtual/física.

\item Implementado mediante memorias asociativas.

\item Tamaño típico: de 32 a 128 entradas.
\end{itemize}

Hay dos tipos fundamentales:
\begin{itemize}
\item Etiquetadas: añaden una marca del espacio de direcciones al que pertenece.

\item No etiquetadas: no poseen la capacidad anterior, la mayoría.
\end{itemize}

Funcionamiento:
\begin{itemize}
\item Si se encuentra la dirección en el TLB se devuelve su traducción.

\item Si no se encuentra es necesario calcular la traducción.
	\begin{itemize}
	\item Hardware: se devuelve la traducción correcta (x86).
	
	\item Software: más lento pero más flexible (PowerPC).
	\end{itemize}

\item Es fundamental conocer la interacción TLB/caché.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{direccionamientocache.png}
\end{figure}

El proceso que sigue generalmente es el siguiente:
\begin{enumerate}
\item Dada una dirección virtual, el procesador primero examina la TLB.

\item Si la entrada de la tabla de páginas solicitada está presente (acierto en la TLB), entonces se recupera el número de marco y se construye la dirección real.

\item Si la entrada de la tabla de páginas no se encuentra (fallo en la TLB), el procesador utiliza el número de página para indexar la tabla de páginas del proceso y examinar la correspondiente entrada de la tabla de páginas.
	
	\begin{enumerate}
	\item Si el bit de presente está puesto a 1, entonces la página se encuentra en memoria principal, y el procesador puede recuperar el número de marco desde la entrada de la tabla de páginas para construir la dirección real. El procesador también autorizará la TLB para incluir este nueva entrada de tabla de páginas.
	
	\item Si el bit presente no está puesto a 1, entonces la página solicitada no se encuentra en memoria principal y se produce un fallo de acceso memoria, llamado \textbf{fallo de página}.
	\end{enumerate}
\end{enumerate}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{TLB.png}
\end{figure}

\newpage

\textbf{Esquemas de direccionamiento de caché}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{esquemacache.png}
\end{figure}

\textbf{Control de Entrada/Salida}

El sistema operativo inicia una operación E/S:
\begin{itemize}
\item Instrucciones especiales: \textbf{in}/\textbf{out} (x86)

\item E/S en memoria: \textbf{mov} (x86)
	\begin{itemize}
	\item Acceso al hardware como direcciones de memoria.
	\item Requiere de una MMU capaz de traducir el bus de E/S.
	\end{itemize}
\end{itemize}

Por otro lado es SO puede averiguar cuando una orden E/S finaliza de las siguientes formas:
\begin{itemize}
\item Sondeo: leer el puerto de estado hasta encontrar el valor adecuado. La CPU continuamente rueba todos y cada uno de los dispositivos conectados a él para detectar si algún dispositivo necesita atención de la CPU. Algoritmo de sondeo:
	\begin{enumerate}
	\item Cuando un dispositivo tiene algún comando para ser ejecutado por la CPU, comprueba continuamente el bit de ocupado de la CPU hasta que se borra (0).
	
	\item Cuando se borra el bit de ocupado, el dispositivo establece el bit de escritura en su registro de comando y escribe un byte en el registro de salida de datos.
	
	\item Ahora el dispositivo establece (1) el bit de comando listo.
	
	\item Cuando la CPU verifica el bit de comando listo y lo encuentra establecido (1), establece (1) su bit de ocupado.
	
	\item Luego, la CPU lee el registro de comando del dispositivo y ejecuta el comando del dispositivo.
	
	\item Después de la ejecución del comando, la CPU borra (0) el bit de comando listo, el bit de error del dispositivo para indicar la ejecución exitosa del comando del dispositivo y además borra (0) su bit de ocupado para indicar que la CPU está libre para ejecutar el comando de algún otro dispositivo.
	\end{enumerate}	 

\item Interrupción: existe una línea física mediante la cual se avisa del fin de la operación y se cede el control al SO. Procesamiento de interrupciones:
	\begin{enumerate}
	\item El dispositivo genera una señal de interrupción hacia el procesador.
	
	\item El procesador termina la ejecución de la instrucción actual antes de responder a la interrupción.
	
	\item El procesador comprueba si hay petición de interrupción pendiente, determina que hay una y manda y una señal de reconocimiento al dispositivo que produjo la interrupción. Este reconocimiento permite que el dispositivo elimine su señal de interrupción.
	
	\item En ese momento, el procesador necesita prepararse para transferir el control a la rutina de interrupción. Para comenzar, necesita salvar la información requerida para reanudar el programa actual en el momento de la interrupción. La información mínima requerida es la palabra de estado del programa (PSW) y la posición de la siguiente instrucción que se va a ejecutar, que está contenida en el contador de programa. Esta información se peude apilar en la pila de control de sistema.
	
	\item A continuación, el procesador carga del contador del programa con la posición del punto de entrada de la rutina de interrupción que responderá a esta interrupción. Dependiendo de la arquitectura de computador y del diseño del sistema operativo, puede haber un único programa, uno por cada tipo de interrupción o uno por cada dispositivo y tipo de interrupción. Si hay más de una rutina de manejo de interrupción, el procesador debe determinar cuál invocar. Esta información puede estar incluida en la señal de interrupción original o el procesador puede tener que realizar una petición al dispositivo que generó la interrupción para obtener una respuesta que contiene la información requerida.
	
	\item En este momento, el contador del programa y la PSW vinculados con el programa interrumpido se han almacenado en la pila del sistema. Sin embargo, hay otra información que se considera parte del estado del programa en ejecución. En concreto, se necesita salvar el contenido de los registros del procesador, puesto que estos registros los podría utilizar el manejador de interrupciones. Por tanto, se deben salvar todos estos valores, así como cualquier otra información de estado. Generalmente, el manejador de interrupción comenzará salvando el contenido de todos los registros en pila. 
	
	\item El manejador de interrupción puede en este momento comenzar a procesar la interrupción. Esto incluirá un examen de la información de estado relacionada con la operación de E/S o con otro evento distinto que haya causado la interrupción. Asimismo, puede implicar el envío de mandtos adicionales o reconocimientos al dispositivo de E/S.
	
	\item Cuando se completa el procesamiento de la interrupción, se recuperarn los valores de los registros salvados en la pila y se restituyen los registros.
	
	\item La última acción consiste en restituir de la pila los valores de la PSW y del contador del programa. Como resultado, la siguiente instrucción que se va a ejecutar corresponderá al programa previamente interrumpido.
	\end{enumerate}


\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{interrupciones.png}
\end{figure}

\textbf{Eventos:excepciones e interrupciones}

Eventos o "situaciones especiales":
\begin{itemize}
\item Excepciones (síncronas): llamadas al sistema.

\item Interrupciones (asíncronas): fin de operación de DMA.
\end{itemize}

Hay otras diferencias como el origen, la predictibilidad o la reproducibilidad. El manejo de excepciones e interrupciones debe producirse a tiempo y es específico para cada tipo de procesador.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{eventos.png}
\end{figure}

\textbf{Interrupciones software (int/syscall - swi)}

Se tratan de un mecanismo para ceder el contro al SO elevando el nivel de privilegio. Son síncroncas, predecibles y reproducibles, luego aunque se llamen interrupciones son excepciones. 

Un mismo programa aislado siempre provoca las mismas:
\begin{itemize}
\item Instrucción desconocida.
\item Instrucción errónea (divisón entre 0).
\item Modo de direccionamiento erróneo.
\item Violación del espacio de direcciones.
\item Llamada al sistema.
\item Fallo de página (solo políticas de paginación locales).
\end{itemize}

Deben atenderse, sino se daría un comportamiento erróneo. Producen una sobrecarge en espacio y tiempo fuera del programa que la solicita.\\

\textbf{Interrupciones}

Se trata de un mecanismo para solicitar la atención de la CPU. Son asíncronas, no predecibles y no reproducibles. Un periférico puede solicitar una interrupción independientemente del estado de la CPU o el proceso actual.

Ejemplos:
	\begin{itemize}
	\item Eventos externos: sensores
	\item Final de una operación DMA.
	\item Final de una operación E/S.
	\end{itemize}

\end{document}
