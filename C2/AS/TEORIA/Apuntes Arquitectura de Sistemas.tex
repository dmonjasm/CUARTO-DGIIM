\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[colorlinks]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\graphicspath{ {images/} }

\author{Daniel Monjas Miguélez}

\title{Apuntes de Arquitectura de Sistemas}

\begin{document}
\maketitle

\newpage

\tableofcontents

\newpage

\section{Tema 1: Soporte Hardware}
\subsection{Motivación}
\begin{figure}[h]
\centering
\includegraphics[scale=0.8,width=\textwidth]{gestion_memoria.png}
\end{figure}
\newpage

Para una matriz de tamaño $10000\times 10000$:
\begin{figure}[h]
\centering
\includegraphics[scale=0.8,width=\textwidth]{time.png}
\end{figure}

La causa de este fenómeno es la forma en que C gestiona la memoria, pues C/C++ almacenan las matrices por filas. Ejemplo: $int\:\:m[4][4]$
\begin{figure}[h]
\centering
\includegraphics[scale=0.6,width=80mm]{ejemplo4x4.png}
\end{figure}

\textbf{Memoria Virtual}

Es una utilidad que permite a los programas direccionar la memoria desde un punto de vista lógico, sin importar la cantidad de memoria principal física disponible. Se concebió como método para tener múltiples trabajos de usuario residiendo en memoria principal de forma concurrente, de forma que no exista un intervalo de tiempo de espera entre la ejecución de procesos sucesivos, es decir, mientras un proceso se escribe en almacenamiento secundario y se lee el sucesor. Se introdujeron los sistemas de paginación, que permiten que los procesos se compriman en un número determinado de bloques de tamaño fijo, denominados páginas. Un programa referencia a una palabra por medio de una dirección virtual, que consiste en un número de página y un desplazamiento dentro de la página.

Todas las páginas de un proceso se mantienen en disco. Cuando un proceso está en ejecución, algunas de sus páginas se encuentran en memoria principal, y si se referencia a una página que no está en memoria principal el hardware de gestión de memoria lo detecta y permite que la página que falta se cargue (carga bajo demanda).

\subsection{Clasificación}
\subsubsection{Clasificación "práctica" de arquitecturas paralelas}
\begin{itemize}
\item Multiprocesadores de memoria compartida:
	\begin{itemize}
	\item SMT(Simultaneos Multithreading/Hyperthreading): permite a una única CPU ejecutar varios flujos de control. Esto requiere tener múltiples copias de algunos componentes hardware de la CPU, como contadores de programa y registros de archivo, mientras otras partes siguen siendo únicas como las unidades que realizan aritmética con punto flotante. Cuando un procesador tiene Hyper-Threading puede tener de 2 a 64 hebras (puede tener más, veanse procesadores de servidor), dependiendo del número de núcleos físicos del mismo.
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=\textwidth]{Hyperthreading.jpg}
	\end{figure}
	
	\item SMP(Symmetric Multi-Processing): el núcleo puede ejecutar en cualquier procesador, y normalmente cada procesador realiza su propia planificación del conjunto disponible de procesos e hilos. El núcleo puede construirse como múltiples procesos o múltiples hilos, permitiéndose la ejecución de partes del núcleo en paralelo. El enfoque SMP complica el sistema operativo, ya que debe asegurar que dos procesadores no seleccionan un mismo proceso y que no se pierde ningún proceso de la cola. Se deben emplear técnicas para resolver y sincronizar el uso de los recursos. Suelen tener entre 2 y 256 procesadores.
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=\textwidth]{SMP.png}
	\end{figure}
	
	\item UMA/ccNUMA (Uniforma Memory Access/Cache Coherent  UMA): Se define como la situación en la cual el acceso a cualquier RAM desde CPU toma siempre la misma cantidad de tiempo. Suele tener entre 2 y 4096 procesadores.
	
	\end{itemize}
	
\item Multiprocesadores masivamente paralelos:
	\begin{itemize}
	
	\item NUMA/ccNUMA (Non Uniform Memory Access/ Cache Coherent NUMA): A diferencia de UMA, algunas partes de la memoria pueden tomar más tiempo de acceso que otras, creando una penalización en el rendimiento. Esta penalización se puede minimizar por medio de la administración de recursos.
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=65mm]{umanuma.png}
	\end{figure}
	
	\item Paso de mensajes/NoRMA (No Remote Memory Access): en las arquitecturas NoRMA, el espacio de direcciones global no es único y la memoria no es globalmente accesible desde todos los procesadores. El acceso a modulos de memoria remotos es solo posible indirectamente a través del paso de mensajes por medio de la red de interconexión a otros procesadores, lo que en respuesta recibirá los datos buscados en un mensaje de respuesta.
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=80mm]{NORMA.jpg}
	\end{figure}
	\end{itemize}
	
\item Cluster$\rightarrow$+10M procesadores. Al igual que los sistemas multiprocesadores, los sistemas clústes juntan múltiples CPUs para conseguir un trabajo computacional. La diferencia respecto a los sistemas multiprocesadores en que los clústers se componen de dos o más sistemas individuales unidos juntos, a los que se denominan nodos.
	\begin{itemize}
	\item GPUs
	\end{itemize}
	
	\begin{figure}[h]
	\centering
	\includegraphics[scale=1,width=70mm]{cluster.png}
	\end{figure}
\end{itemize}

\subsubsection{Clasificación Arquitectura de Computadores}
\begin{itemize}
\item Sistemas monoprocesador
	\begin{itemize}
	\item Bus único
	\item Buses separados/especializados
	\end{itemize}
\item Sistemas multiprocesador
	\begin{itemize}
	\item Multiproceso simétrico (SMP)
	\item Multihebra simultánea (SMT)
	\item Multinúcleo (SMP)
	\end{itemize}
	
\item Sistemas distribuidos
\end{itemize}

\textbf{Sistema monoprocesador:} Es el modelo más simple, pues conecta todo en un bus común.
\begin{itemize}
\item Ventaja$\rightarrow$ precio.
\item Inconveniente $\rightarrow$ infrautilización de componentes por la diferencia de velocidad.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=70mm]{monoprocesador.png}
\end{figure}

Una posible solución para la diferencia de velocidad es aislar los componentes por velocidad y conectarlos por medio de un puente

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=50mm]{solucionmonoprocesador.png}
\end{figure}
\newpage
Otra posible solución incluso mejor es separar el bus de E/S en dos buses en función de los dispositivos E/S más rápidos y más lentos, y conectar ambos buses por medio de un puente isa.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{sol2monoprocesador.png}
\end{figure}

\textbf{Sistema multiprocesador: multiproceso simétrico}. Lo más simple es conectar todos los elementos a un bus común.
\begin{itemize}
\item Ventaja $\rightarrow$ precio.

\item Inconveniente $\rightarrow$ se agrava la infrautilización de componentes.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{multiprocesador.png}
\end{figure}

\newpage

\textbf{Sistemas multiprocesador: multihebra simultánea}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{multiprocesador-multihebra.png}
\end{figure}

\textbf{Sistemas multiprocesador: multiproceso simétrico}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{multiprocesador-multihebra2.png}
\end{figure}

\newpage

\textbf{Sistemas multiprocesador actuales}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=140mm]{multiprocesador_actual.png}
\end{figure}

\textbf{Arquitecturas de un sistema actual}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{arquitectura_actual.png}
\end{figure}

\subsubsection{Componentes}
\textbf{Componentes básicos}
\begin{itemize}
\item Procesadores
\item Jerarquía de memoria.

Surge el problema de que cuanto menor es el tiempo de acceso mayor es el coste por bit, y que cuanto mayor es la capacidad menor la velocidad de acceso. Para lidiar con este dilema surge la jerarquía de memoria. En la jerarquía de memoria según se desciende disminuye el coste por bit, aumenta la capacidad, aumenta el tiempo de acceso y se reduce la frecuencia de acceso a ese nivel de la jerarquí por parte del procesador.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{jerarquiamemoria.png}
\end{figure}


\item Buses de interconexión: AGP, Hypertransport, IDE, IEEE 1394, ISA, M.2, PCI, PCIe, SATA, SCSI, USB, ...
\item Entrada/Salida: controladores, canales de DMA, procesadores de E/S,...
\item Periféricos: altavoz, disco, impresora, micrófono, monitor, ratón, teclado, ...
\end{itemize}

\subsubsection{Procesador}
\textbf{Interfaz del procesador}
\begin{itemize}
\item Conjunto de instrucciones
	\begin{itemize}
	\item transferencia: \begin{verbatim}
	in, mov, out,...
	\end{verbatim}
	
	\item modificación: \begin{verbatim}
	add, and, div, mul, or, sub,...
	\end{verbatim}
	
	\item control: \begin{verbatim}
	cli, sti,...
	\end{verbatim}
	
	\href{http://jegerlehner.ch/intel/IntelCodeTable_es.pdf}{Chuleta instrucciones 8086}
	\end{itemize}

\item Registros generales y especiales

\item Al menos dos modos de ejecución con diferentes privilegios:
	\begin{itemize}
	\item privilegiado: acceso completo
	\item no privilegiado: acceso limitado $\Rightarrow$ excepción
	\end{itemize}
	
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{privilegios.png}
\end{figure}
\end{itemize}

\href{https://upload.wikimedia.org/wikipedia/commons/4/41/Table_of_x86_Registers.png}{Registros del procesador: familia x86-64} \\

En el modo núcleo (modo privilegiado, modo kernel, ...) se pueden ejecutar instrucciones privilegiadas y se puede accesder a áreas de memoria protegidas. Sóla mente el núcleo o kernel del sistema operativo puede ejecutar instrucciones en modo privilegiado. Algunos ejemplos de instrucciones privilegiadas son:

\begin{itemize}
\item Acceso a los dispositivos de E/S: consultar el estado de los dispositivos de E/S, llevar a cabo DMA (Direct Memory Access), atrapar interrupciones.

\item Manipular la unidad de gestión de memoria (MMU): manipualar las tablas de segmento y páginas, cargar y vaciar el búfer de traducción anticipada (TLB)

\item Configurar varios modos de funcionamiento: nivel de prioridad de interrupciones, alterar el vector de interrupción.

\item Utilizar la instrucción $halt$ para activar el modo de ahorro de energía. Esta instrucción detiene abruptamente la CPU hasta que la siguiente interrupción externa ha sido tratada. También es común que se ejecute cuando no hay trabajo inmediato que ejecutar, de forma que se pone al procesador en un estado ocioso.
\end{itemize}

El procesador comprueba el nivel de privilegio en la ejecución de cada instrucción. Los posibles cambios de privilegio son:

\begin{itemize}
\item Usuario $\Rightarrow$ Núcleo: ganar privilegios
	\begin{itemize}
	\item Al arrancar.
	\item Llamada al sistema.
	\item Interrupción hardware.
	\item Excepción.
	\end{itemize}
	
\item Núcleo $\Rightarrow$ Usuario: perder privilegios
	\begin{itemize}
	\item El sistema operativo prepara el entorno necesario para que la aplicación comience su ejecución.
	
	\item El sistema operativo termina alguna de sus actividades y devuelve el control a la aplicación.
	\end{itemize}
\end{itemize}

\textbf{Ciclo de instrucción:} se denomina ciclo de instrucción al procesamiento requerido por una única instrucción. El ciclo de instrucción básco es:

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{ciclo_instruccion.png}
\end{figure}

\begin{itemize}
\item El procesador capta una instrucción desde memoria.

\item La instrucción debe ser decodificada para averiguar su tipo.

\item Conocido el tipo puede ser necesario la captación de nuevos operandos.

\item Se ejecuta la instrucción.

\item Se almacenan los resultados de la ejecución.

\item El proceso se repite instrucción a instrucción hasta que el programa termina.
\end{itemize}

\textbf{Tendencias en el diseño de procesadores}
\begin{itemize}
\item CISC (Complex Instruction Set Computing)$\Rightarrow$ RISC (Reduced Instruction Set Computing) $\Rightarrow$ VLIW (Very Long Instruction Word).

\textbf{CISC}: Es un tipo de diseño de microprocesador. Este contiene un conjunto de instrucciones muy grande que van desde instrucciones muy simples a instrucciones muy especializadas. Se introducen instrucciones que en un diseño RISC se requieren de varias instrucciones, reduciendo así el número de instrucciones de los programas, pero al ser instrucciones más complejas acaban requiriendo más ciclos de reloj para su ejecución.\\

\textbf{RISC}: Como su nombre dice se trata de un diseño de microprocesador. Este diseño contiene instrucciones muy simples y con la combinación de ellas se puede obtener cualquier programa. Si bien su ejecución es rápida, pues son instrucciones muy simples, su tamaño en memoria puede llegar a ser muy grande, pues la ejecución de un programa simple puede requerir de muchas instrucciones RISC.

\textbf{VLIW}: se trata de un procesador segmentado que puede terminar más de una operación por ciclo en el que el compilador es el principal responsable de agrupar operaciones que pueden procesarse en paralelo para definir instrucciones que, de esta forma, se codifican a través de las denominadas palabras de instrucción larga (LIW) o muy larga (VLIW)

\item Ejecución concurrente sobre procesadores: intento de explotación del paralelismo entre instrucciones (ILP). ILP es una mediad de cuántas operaciones pueden ejecutarse simultáneamente sin afectar al resultado.
\end{itemize}

\textbf{Técnicas de explotación de ILP}
\begin{itemize}
\item \textbf{Segmentación de cauce:} la ejecución de múltiples instrucciones puede solaparse total o parcialmente. 

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{segmentacion.png}
\end{figure}

\item \textbf{Ejecución superescalar:} múltiples unidades de ejecución se utilizan para ejecutar múltiples instrucciones en paralelo. Un procesador superescalar es un procesador segmentado que puede finalizar más de una instrucción por ciclo y que posee recursos hardware para extraer el paralelismo entre instrucciones. Para aprovechar al máximo el procesamiento de instrucciones en paralelo que proporcionan las distintas estapas, el procesador incluye una serie de elementos como ventanas de instruccioens o estaciones de buffers, buffers de renombramiento, buffers de reordenamiento, etc.

\item \textbf{Computación con instrucciones explícitamente paralelas (EPIC):} uso del compilador en lugar de complejos circuitos para identificar y explotar el ILP. La intención era permiter un escalado simple del rendimiento sin disparar las frecuencias del reloj. Tiene su base en VLIW.

\item \textbf{Ejecución fuera de orden:} ejecución de instrucciones en cualquier orden que no viole las dependencias entre instrucciones. El orden de ejecución depende de la disponibilidad de los datos de entrada y las unidades de ejecución, no del orden original del programa.

\item \textbf{Renombrado de registros:} técnica para evitar la innecesaria serialización de instrucciones por la reutilización de registros. Puede ser aplicado por el propio compilador al asignar los registros de la arquitectura, pero también puede implementarse en hardware. Esto es lo usual en procesadores superescalares, donde se incluyen estructuras de buffers con una serie de campos específicos (por ejemplo, buffers de renombramiento).

\item \textbf{Ejecución especulativa:} permitir la ejecución de instrucciones completas, o partes, antes de conocer con seguridad si su ejecución debe tener lugar. De esta forma se previene el retraso que habría, de tener que hacer el procesamiento después de saber que es necesario. Si resulta que el procesamiento no era necesario, los cambios realizados se revierten y los resultados se ignoran.

\item \textbf{Predicción de salto:} se utiliza para evitar quedar parado antes de que se resuelvan las dependencias de control. Se utiliza en conjuntción con la ejecución especulativa. Se basa en determinar la alternativa más probable, y continuar el procesamiento, tras las instrucción de salto, con la secuencia de instrucciones que corresponde a dicha opción más probable. Cuando la condición de salto se evalúa, se comprueba si la predicción que se había hecho era correcta o no. Si no lo era habrá que retomar el procesamiento a partir de la primera instrucción de la alternativa que no se tomó, es decir, de la menos probable.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{predicionsalto.png}
\end{figure}

\item \textbf{Multihebra simultánea (SMT):} técnica que permite la ejecución de múltiples hebras de ejecución para aprovechar mejor las unidades funcionales de los procesadores superescalares.
\end{itemize}

\subsubsection{Memoria}

\textbf{Jerarquía de memoria:} Se requiere de jerarquía de memoria entre otras cosas por la gran diferencia de velocidad entre procesador y memoria. La jerarquía de memoria puede aliviar este problema gracias a \textbf{los principios de localidad} y a la \textbf{regla 90/10}:
\begin{itemize}
\item Localidad \textbf{espacial:} la información a la que se accede suelen estar próxima a la que ha sido accedida con anterioridad.

\item Localidad \textbf{temporal:} la información a la que se accede una vez suele volver a ser utilizada.

\item Regla 90/10: el 10\% del código realiza el 90\% del trabajo.
\end{itemize}

\textbf{Tipos de memoria RAM}:
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{tiposram.png}
\end{figure}
\begin{itemize}
\item SRAM (Statica random-access memory): Es un tipo de memoria que utiliza circuitería flip-flop para almacenar cada bit. La diferencia con una DRAM es que la segunda debe de refrescarse periódicamente. La SRAM es más rápida y más cara que la DRAM. Se utiliza típicamente para la caché y los registros internos de la CPU mientras que la DRAM se utiliza para la memoria principal.

\item DDR SDRAM I (Double Data Rate Synchronous RAM): Entre otras cosas las memorias DDR como su nombre indica tienen dos ciclos de reloj, es decir se hace un envío de información cuando el reloj sube y otro cuando el reloj baja. Con esto hace que una memoria DDR con una frecuencia de reloj x duplique el ancho de banda de una SDR SDRAM con igual frecuencia de reloj. Este tipo de memoria se ha visto superada por las versiones 2, 3, 4 y 5 de la misma. Ninguno de sus sucesores tienen compatibilidad ni con su predecesor ni con su sucesor, lo que quiere decir que una RAM DDR1 SDRAM no es compatible con DDR2, DDR3, .... 
\item DDRAM II
\end{itemize}

\textbf{Cantidad de memoria en registros}
\begin{itemize}
\item Tipos de registros:

\item RISC:
	\begin{itemize}
	\item 32 de propósito general (32 ó 64 bits)
	\item 32 de punto flotante (64 bits IEEE 754)
	\item multimedia (64,...,256 bits)
	\end{itemize}

\item CISC: 
	\begin{itemize}
	\item IA32: 8 de propósito general, 8 de punto flotante, 8 multimeida.
	\item IA64: 128 de propósito general, 128 de punto flotante.
	\end{itemize}

\item Algunos procesadores tienen varios conjuntos de estos registros (ventanas de registros)
\end{itemize}

\textbf{Análisis de una jerarquía de dos niveles}
\begin{equation*}
\overline{T}_{acceso}=(1-T_{fallos})\times T_{cache}+T_{fallos}\times(T_{cache}+T_{ram})
\end{equation*}

\textbf{Parámetros de diseño de memorias caché}
\begin{itemize}
\item Tamaño:
	\begin{itemize}
	\item L1:8,...,256KB
	\item L2:1,...,16MB
	\item L3:4,...,128MB
	\end{itemize}
	
\item Tamaño de bloque: 32,...,128B

\item Tiempo de acceso: 1,...,10ns

\item Política de búsqueda:
	\begin{itemize}
	\item bajo demanda
	\item anticipativas
	\end{itemize}

\item Política de colocación:
	\begin{itemize}
	\item correspondencia directa: el bloque $B_j$ de memoria principal se puede ubicar sólo en el marco de bloque que cumple la siguiente relación $i=j\mod{m}$, donde $m$ es el número total de líneas que tiene la cache.
	
	\item asociativa por conjuntos: En la corresponcencia asociativa por conjuntos las líneas de memoria caché se agrupan en $v=2^d$ conjunto con $k$ líneas/conjuto o vías. Se cumple que el número total de marcos de bloque que tiene la caché $m=v*k$. Un bloque $B_j$ de memoria principal se puede ubicar sólo en el conjunto $C_i$ de memoria caché que cumple la siguiente relación $i=j\mod{v}$.
	
	\item completamente asociativa: la caché se organiza en un único conjunto de caché con varias líneas de caché. Un bloque de memoria puede ocupar cualquiera de las lineas de caché. La organización de la caché se puede enmarcar como una matriz de filas (1*m).
	\end{itemize}
	
\item Política de reemplazo:
	\begin{itemize}
	\item LRU
	\item FIFO
	\item aleatoria
	\end{itemize}

\item Política de actualización:
	\begin{itemize}
	\item escritura directa
	\item post-escritura
	\end{itemize}

\item Otras características importantes:
	\begin{itemize}
	\item caché de víctimas
	\item inclusiva/exclusiva
	\item unificada/separada
	\end{itemize}
\end{itemize}

\textbf{Políticas de colocación: correspondencia directa}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=85mm]{correspondenciadirecta.png}
\end{figure}
\newpage

\textbf{Políticas de colocación: correspondencia totalmente asociativa}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=85mm]{totalmenteasociativa.png}
\end{figure}

\newpage

\textbf{Políticas de colocación: correspondencia asociativa por conjuntos (2 M/C)}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=85mm]{porconjuntos.png}
\end{figure}

\textbf{Protección de memoria.}

El sistema operativo debe proteger a los programas entre sí y a él mismo de programas maliciosos o erróneos. Este problema se soluciona utilizando los llamados espacios de direcciones (AS, Address Space). El espacio de direcciones de un computador corresponde al rango de direcciones disponible para un programa de computador.

El procesador dispone de recursos para establecer límites al espacio de direcciones de memoria accesibles por los programas: memoria virtual.

\begin{figure}
\centering
\includegraphics[scale=1,width=\textwidth]{memvirtual.png}
\end{figure}
\newpage

Hay varias implementaciones:

\begin{itemize}
\item Segmentaciones: tamaño variable y arbitrario.
	\begin{itemize}
	\item registro base: principio del espacio de direcciones.
	\item registro límite: tamaño del espacio de direcciones.
	\end{itemize}

\item Paginación: tamaño variable en múltiplos de página.
	\begin{itemize}
	\item tablas de páginas: lista de páginas de un proceso.
	\end{itemize}
\end{itemize} 

La mayoría de los SO asocian un espacio de direcciones diferente para cada proceso (salvo SASOS, Single Adrress Space Operating System):
\begin{itemize}
\item Ventaja $\Rightarrow$ protección automática.

\item Inconveniente $\Rightarrow$ dificulta la compartición
\end{itemize}

Las partes de un espacio de direcciones pueden colocarse en cualquier parte de la memoria física. Algunos espacios de direcciones deben ocupar lugares específicos de la memoria física, ej: dispositivos de E/S.

El procesador debe tener una unidad de gestión de memoria (MMU, Memory Management Unit) extremadamente eficiente porque la traducción entre direcciones virtual-física puede realizarse más de una vez por instrucción. Se requiere una traducción por cada acceso a memoria.\\

\textbf{Traducción de dirección virutal a dirección física}
\begin{enumerate}
\item La ejecución de una instrucción puede requerir varias traducciones, por ejemplo:
	\begin{itemize}
	\item Captacińo de la instrucción.
	
	\item Captación del dato.
	
	\item Escritura del resultado.
	\end{itemize}
	
\item Cada traducción puede requerir varios accesos a memoria:
	\begin{itemize}
	\item Segmentación + paginación.
	
	\item Tablas de página multinivel.
	\end{itemize}
	
\item Se necesita una tabla de traducción por cada espacio de direcciones.

\item Dependerá del tamaño de las direcciones virtuales y físicas, pero habrán al menos tantas entradas como páginas tenga el proceso.
\end{enumerate}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{traduccion.png}
\end{figure}
\newpage

\textbf{Fucnionamiento de la segmentación (x86)}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{segmentacionx86.png}
\end{figure}
\newpage

\textbf{Segmentación + paginación (x86\_64)}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{segmentacionpaginacion.png}
\end{figure}

\textbf{Tabla de páginas multinivel (x86\_64)}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=85mm]{tabla_multinivel.png}
\end{figure}

\newpage

\textbf{Estructura habitual tabla de páginas}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{estructuratabla.png}
\end{figure}

\subsubsection{Interacción}
\textbf{Buffer de traducción anticipada (TLB)}

Traducir direcciones por software es muy lento, mientras que mediante hardware puede hacerse más rápido y además podemos añadir una caché de traducciones (TLB). En principio, toda referencia a la memoria virtual puede causar dos accesos a memoria física, uno para buscar la entrada en la tabla de página apropiada y otra para buscar los datos solicitados. De esa forma, el esquema de memoria virtual básico causaría el efecto de duplicar el tiempo de acceso a la memoria. Para solventar este problema, la mayoría de esquemas de la memoria virtual utilizan una \textit{cache} especial de alta velocidad para las entradas de la tabla de páginas, habitualmente denominada buffer de traducción anticipada. TLB:
\begin{itemize}
\item Conenido: pares de direcciones virtual/física.

\item Implementado mediante memorias asociativas.

\item Tamaño típico: de 32 a 128 entradas.
\end{itemize}

Hay dos tipos fundamentales:
\begin{itemize}
\item Etiquetadas: añaden una marca del espacio de direcciones al que pertenece.

\item No etiquetadas: no poseen la capacidad anterior, la mayoría.
\end{itemize}

Funcionamiento:
\begin{itemize}
\item Si se encuentra la dirección en el TLB se devuelve su traducción.

\item Si no se encuentra es necesario calcular la traducción.
	\begin{itemize}
	\item Hardware: se devuelve la traducción correcta (x86).
	
	\item Software: más lento pero más flexible (PowerPC).
	\end{itemize}

\item Es fundamental conocer la interacción TLB/caché.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{direccionamientocache.png}
\end{figure}

El proceso que sigue generalmente es el siguiente:
\begin{enumerate}
\item Dada una dirección virtual, el procesador primero examina la TLB.

\item Si la entrada de la tabla de páginas solicitada está presente (acierto en la TLB), entonces se recupera el número de marco y se construye la dirección real.

\item Si la entrada de la tabla de páginas no se encuentra (fallo en la TLB), el procesador utiliza el número de página para indexar la tabla de páginas del proceso y examinar la correspondiente entrada de la tabla de páginas.
	
	\begin{enumerate}
	\item Si el bit de presente está puesto a 1, entonces la página se encuentra en memoria principal, y el procesador puede recuperar el número de marco desde la entrada de la tabla de páginas para construir la dirección real. El procesador también autorizará la TLB para incluir este nueva entrada de tabla de páginas.
	
	\item Si el bit presente no está puesto a 1, entonces la página solicitada no se encuentra en memoria principal y se produce un fallo de acceso memoria, llamado \textbf{fallo de página}.
	\end{enumerate}
\end{enumerate}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{TLB.png}
\end{figure}

\newpage

\textbf{Esquemas de direccionamiento de caché}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{esquemacache.png}
\end{figure}

\textbf{Control de Entrada/Salida}

El sistema operativo inicia una operación E/S:
\begin{itemize}
\item Instrucciones especiales: \textbf{in}/\textbf{out} (x86)

\item E/S en memoria: \textbf{mov} (x86)
	\begin{itemize}
	\item Acceso al hardware como direcciones de memoria.
	\item Requiere de una MMU capaz de traducir el bus de E/S.
	\end{itemize}
\end{itemize}

Por otro lado es SO puede averiguar cuando una orden E/S finaliza de las siguientes formas:
\begin{itemize}
\item Sondeo: leer el puerto de estado hasta encontrar el valor adecuado. La CPU continuamente rueba todos y cada uno de los dispositivos conectados a él para detectar si algún dispositivo necesita atención de la CPU. Algoritmo de sondeo:
	\begin{enumerate}
	\item Cuando un dispositivo tiene algún comando para ser ejecutado por la CPU, comprueba continuamente el bit de ocupado de la CPU hasta que se borra (0).
	
	\item Cuando se borra el bit de ocupado, el dispositivo establece el bit de escritura en su registro de comando y escribe un byte en el registro de salida de datos.
	
	\item Ahora el dispositivo establece (1) el bit de comando listo.
	
	\item Cuando la CPU verifica el bit de comando listo y lo encuentra establecido (1), establece (1) su bit de ocupado.
	
	\item Luego, la CPU lee el registro de comando del dispositivo y ejecuta el comando del dispositivo.
	
	\item Después de la ejecución del comando, la CPU borra (0) el bit de comando listo, el bit de error del dispositivo para indicar la ejecución exitosa del comando del dispositivo y además borra (0) su bit de ocupado para indicar que la CPU está libre para ejecutar el comando de algún otro dispositivo.
	\end{enumerate}	 

\item Interrupción: existe una línea física mediante la cual se avisa del fin de la operación y se cede el control al SO. Procesamiento de interrupciones:
	\begin{enumerate}
	\item El dispositivo genera una señal de interrupción hacia el procesador.
	
	\item El procesador termina la ejecución de la instrucción actual antes de responder a la interrupción.
	
	\item El procesador comprueba si hay petición de interrupción pendiente, determina que hay una y manda y una señal de reconocimiento al dispositivo que produjo la interrupción. Este reconocimiento permite que el dispositivo elimine su señal de interrupción.
	
	\item En ese momento, el procesador necesita prepararse para transferir el control a la rutina de interrupción. Para comenzar, necesita salvar la información requerida para reanudar el programa actual en el momento de la interrupción. La información mínima requerida es la palabra de estado del programa (PSW) y la posición de la siguiente instrucción que se va a ejecutar, que está contenida en el contador de programa. Esta información se peude apilar en la pila de control de sistema.
	
	\item A continuación, el procesador carga del contador del programa con la posición del punto de entrada de la rutina de interrupción que responderá a esta interrupción. Dependiendo de la arquitectura de computador y del diseño del sistema operativo, puede haber un único programa, uno por cada tipo de interrupción o uno por cada dispositivo y tipo de interrupción. Si hay más de una rutina de manejo de interrupción, el procesador debe determinar cuál invocar. Esta información puede estar incluida en la señal de interrupción original o el procesador puede tener que realizar una petición al dispositivo que generó la interrupción para obtener una respuesta que contiene la información requerida.
	
	\item En este momento, el contador del programa y la PSW vinculados con el programa interrumpido se han almacenado en la pila del sistema. Sin embargo, hay otra información que se considera parte del estado del programa en ejecución. En concreto, se necesita salvar el contenido de los registros del procesador, puesto que estos registros los podría utilizar el manejador de interrupciones. Por tanto, se deben salvar todos estos valores, así como cualquier otra información de estado. Generalmente, el manejador de interrupción comenzará salvando el contenido de todos los registros en pila. 
	
	\item El manejador de interrupción puede en este momento comenzar a procesar la interrupción. Esto incluirá un examen de la información de estado relacionada con la operación de E/S o con otro evento distinto que haya causado la interrupción. Asimismo, puede implicar el envío de mandtos adicionales o reconocimientos al dispositivo de E/S.
	
	\item Cuando se completa el procesamiento de la interrupción, se recuperarn los valores de los registros salvados en la pila y se restituyen los registros.
	
	\item La última acción consiste en restituir de la pila los valores de la PSW y del contador del programa. Como resultado, la siguiente instrucción que se va a ejecutar corresponderá al programa previamente interrumpido.
	\end{enumerate}


\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{interrupciones.png}
\end{figure}

\textbf{Eventos:excepciones e interrupciones}

Eventos o "situaciones especiales":
\begin{itemize}
\item Excepciones (síncronas): llamadas al sistema.

\item Interrupciones (asíncronas): fin de operación de DMA.
\end{itemize}

Hay otras diferencias como el origen, la predictibilidad o la reproducibilidad. El manejo de excepciones e interrupciones debe producirse a tiempo y es específico para cada tipo de procesador.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{eventos.png}
\end{figure}

\textbf{Interrupciones software (int/syscall - swi)}

Se tratan de un mecanismo para ceder el contro al SO elevando el nivel de privilegio. Son síncroncas, predecibles y reproducibles, luego aunque se llamen interrupciones son excepciones. 

Un mismo programa aislado siempre provoca las mismas:
\begin{itemize}
\item Instrucción desconocida.
\item Instrucción errónea (divisón entre 0).
\item Modo de direccionamiento erróneo.
\item Violación del espacio de direcciones.
\item Llamada al sistema.
\item Fallo de página (solo políticas de paginación locales).
\end{itemize}

Deben atenderse, sino se daría un comportamiento erróneo. Producen una sobrecarge en espacio y tiempo fuera del programa que la solicita.\\

\textbf{Interrupciones}

Se trata de un mecanismo para solicitar la atención de la CPU. Son asíncronas, no predecibles y no reproducibles. Un periférico puede solicitar una interrupción independientemente del estado de la CPU o el proceso actual.

Ejemplos:
\begin{itemize}
\item Eventos externos: sensores
\item Final de una operación DMA.
\item Final de una operación E/S.
\end{itemize}

\textbf{Vector de interrupciones}

Se trata del vector que contiene las direcciones de los manejadores de interrupción para los distintos dispositivos conectados y las distintas interrupciones.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{vectorint.png}
\end{figure}

\textbf{Manejo de excepciones e interrupciones}

Los siguientes eventos podríann lanzar una excepción o una interrupción:
\begin{itemize}
\item Señales de periféricos:
	\begin{itemize}
	\item Final de una lectura de disco
	\item Atasco de papel
	\end{itemize}
	
\item Cambio del dominio de protección (segmentación/paginación).

\item Errores de programación (acceso a dirección inválida).

\item Desbordamiento de memoria (desbordamiento de pila).

\item Paginación bajo demanda.

\item Fallos hardware (paridad de memoria).
\end{itemize}

El manejo del evento se hace durante la ejecución del proceso actualmente en ejecución.\\

\textbf{Efectos de la temporización}

El manejo de cada evento ralentiza la ejecución del programa interrumpido. El resultado de los programas no se pone en peligro, salvo las aplicaciones de tiempo real que si pueden fallar. Esta es una de las razones por las que los programadores no deben confiar en las condiciones de temporización (ej: sincronización). \\

\textbf{Control de interrupciones:}

Las interrupciones pueden llegar en cualquier momento:
\begin{itemize}
\item Usuario modificando datos compartidos.

\item SO realizando una operación no interrumpible.
\end{itemize}

El sistema operativo y el hardware permiten sincronizar actividades concurrentes mediantes operaciones atómicas: secuencias de instrucciones que no pueden ser interrumpidas. \\

Soluciones:
\begin{itemize}
\item Deshabilitar las interrupciones. En una máquina monoprocesador, los procesos concurrentes no pueden solaparse, sólo pueden entrelazarse. Es más, un proceso continuará ejecutando hasta que invoque un servicio del sistema operativo o hasta que sea interrumpido. Por tanto, para garantizar la exclusión mutua, basta con impedir que un proceso sea interrumpido. Esta técnica puede proporcionarse en forma de primitivas definidas por el núcleo del sistema para deshabilitar y habilitar las interrupciones. Esta solución no funcionará sobre una arquitectura multiprocesador. Cuando el sistema de cómputo incluye más de un procesador, es posible (y típico) que se estén ejecutando al tiempo más de un proceso. En este caso, deshabilitar interrupciones no garantiza exclusión mutua.

\item Instrucciones atómicas basadas en leer/modificar/almacenar: En una configuración multiprocesador, varios procesadores comparten acceso a una memoria principal comúnt. No hay mecanismo de interrupción entre procesadores en el que pueda basarse la exclusión mutua. 

A un nivel hardware, el acceso a una posición de memoria excluye cualquier otro acceso a la misma posición. Los diseñadores de hardware han propuesto varias instrucciones que llevan a cabo dos acciones atómicamente, como leer y escribir o leer y comprobar, sobre una única posición de memoria con un único ciclo de búsqueda de instrucción. Durante la ejecución de la instrucción, el acceso a la posición de memoria se le bloquea a toda otra instrucción que referencia esa posición. Estas acciones se realizan (típicamente) en un solo ciclo de instrucción.
	\begin{itemize}
	\item \textbf{tas}: \textit{test and set} (comprueba y establece)
	
	\item \textbf{cmpxchg}: comparar e intercambiar.
	
	\item \textbf{ll/sc}: carga enlazada y almacenamiento condicional.
	\end{itemize}
\end{itemize}

La mayoría de los ordenadores permiten que los ocntroladores de E/S interrumpan la actividad del procesador. La CPU transfiere el control a un manejador de interrupción que normalmente es parte del SO (excepción: controladores en espacio de usuario).

El procesador puede prevenir las interrupciones:
\begin{itemize}
\item Enmascarándolas

\item Deshabilitándolas

\item Estableciendo un nivel mínimo de prioridad.
\end{itemize}

\textbf{Procesamiento de interrupciones}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{procinterrupcion.png}
\end{figure}

\textbf{Ventajas del uso de interrupciones}
\begin{itemize}
\item Los eventos son atendidos más rápidamente

\item No se consume tiempo del procesador para descubrir el final de un evento.

\item Los programas pueden ejecutarse más rápidamente.

\item Se mejora el aprovechamiento del procesador.
\end{itemize}

Con sólo el uso de interrupciones el procesador sigue siendo el encargado de realizar las transferencias de información. La solución ideal es utilizar DMA para evitarlo.\\

\textbf{Múltiples interrupciones}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{multinterrupcion.png}
\end{figure}

\textbf{Técnicas de Entrada/Salida}
\begin{itemize}
\item \textbf{E/S programada (sondeo)}. En E/S programada, el módulo de E/S realiza la acción solicitada y fija los bits correspondiente en el registro de estado de E/S, pero no realiza ninguna acción para avisar al procesador. En concreto, no interrumpe al procesador. Por tanto, después de que se invoca la instrucción de E/S, el procesador debe tomar un papel activo para determinar cuándo se completa la instrucción de E/S. Por eso el procesador comprueba periódicamente el estado del módulo de E/S hasta que se encuentre que se ha completado la operación.

Tiene la desventaja de que es un proceso que consume un tiempo apreciable que mantiene al procesador ocupado innecesariamente.

\item \textbf{E/S dirigida mediante interrupción}. Es una alternativa a la E/S programada. En ella el procesador genera un mandato de E/S para un módulo y, acto seguido, continúa realizando algún otro trabajo útil. El módulo de E/S interrumpirá más tarde al procesador para solicitar su servicio cuando esté listo para intercambiar datos con el mismo. El procesador ejecutará la transferencia de datos, como antes, y después reanudará el procesamiento previo.

El mayor problema de esta alternativa es que el procesador tiene que hacer la transferencia de datos el mismo, cosa que se arreglará con DMA.

\item \textbf{Acceso directo a memoria (DMA)}. La función DMA puede ser llevada a cabo por un módulo separado conectado en el bus del sistema o puede estar incluida en un módulo de E/S. La técnica funciona como sigue, cuando el procesador desea leer o escribir un bloque de datos, genera un mandato de DMA, enviándo la siguiente información:
\begin{itemize}
\item Si se trata de una lectura o una escritura.

\item La dirección del dispositivo de E/S involucrado.

\item La posición inicial de memoria en la que se desea leer los datos o donde se quieren escribir.

\item El número de palabras que se pretende leer o escribir.
\end{itemize}

A continuación, el procesador continúa con otro trabajo. Ha delegado esta operación de E/S al módulo de DMA, que se ocupará de la misma. El módulo de DMA transferirá el bloque completo de datos, palabra a palabra, hacia la memoria o desde ella sin pasar a través del procesador. Por tanto, el procesador solo se involucra al principio y al final.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{DMA.png}
\end{figure}

\textbf{Direccionamiento físico de la memoria principal}

El direccionamiento virtual es algo que sólo existe en el interior del procesador. Para acceder a memoria los controladores de dispositivos y DMA sólo emplean direcciones físicas. Por ejemplo:
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=70mm]{ejemplo1.png}
\end{figure}

Un retraso en la E/S podría provocar que el marco 4096 fuese asignado a otro proceso a través de los mecanismos de segmentación o paginación. La solución a este problema es fijar (\textbf{pinning}) el marco de página durante el tiempo que dure el proceso de transferencia. Fijar (\textbf{pinning}) y liberar (\textbf{unpinning}) es un mecanismo de protección.
\begin{itemize}
\item Usos: soporte de DMA y procesos de tiempo real.

\item Problema: el abuso para acaparar recursos.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=70mm]{pinning.png}
\end{figure}

\textbf{Temporizador}

Los niveles de privilegio son un mecanismo de protección útil para el SO. Los eventos pueden transferir el control al sistema operativo. Si un proceso no genera eventos nunca cede el control del procesador. A este problema hay varias soluciones:

\begin{itemize}
\item La más habitual: generar una interrupción de forma periódica mediante el temporizador, ej: cada 10ms.

\item La más conveniente: reprogramar el temporizador tras cada evento para que sólo genere interrupciones cuando sea necesario.
\end{itemize}

\section{Tema 2: Introducción a los sistemas operativos}
\subsection{Abstracciones}
Se denomina espacio de direcciones a la memoria utilizable por un proceso. Se trata además de una unidad de protección de memoria, pues el hardware de direccionamiento en memoria asegura que un proceso se pueda ejecutar únicamente dentro de su propio espacio de direcciones.

Habitualmente este está formado por 3 componentes:
\begin{itemize}
\item \textbf{Código:} .text

\item \textbf{Datos:} .data, .bss y heap

\item \textbf{Pila:} Stack
	\begin{itemize}
	\item Variables locales
	\item Marcos de procedimiento
	\end{itemize}
\end{itemize}

El tamaño de cada zona es:
\begin{itemize}
\item Código: tamaño fijo

\item Datos: pueden crecer hacia arriba

\item Pila: pueden crecer hacia abajo
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=60mm]{adresspace.png}
\end{figure}
\newpage
\textbf{Procesos y/o hebras:}

Se trata de una unidad de trabajo. Incluye el contexto del procesador (que contiene el contador del programa y el puntero de pila) y su propia áread de datos para una pila (para posibilitar el salto a subrutinas). Un hilo se ejecuta secuencialmente y se puede interrumpir de forma que el procesador pueda dar paso a otro hilo. A parte de la distribución dada hay otras distintas como pueden ser

\begin{itemize}
\item (Porción de) un programa en ejecución.

\item Instancia de un programa ejecutándose.

\item Hebra/hilo/fibra: mínima unidad de ejecución

\item Proceso/tarea: unidad de posesión/protección de recursos.
\end{itemize}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=70mm]{hilos_programa.png}
\end{figure}

\textbf{Comunicación entre procesos}

Hay varios 3 tipos de comunicación entre procesos:

\begin{itemize}
\item Ficheros: tuberías, sockets.
	\begin{itemize}
	\item Tubería: es un \textit{buffer} circular que permite que dos procsos se comuniquen siguiendo el modelo productor consumidor. Por tanto, se trata de una cola de tipo FIFO, en la que se escribe un proceso y se lee otro.
	
	\item Socket: permite la comunicación entre un proceso cliente y un proceso servidor y puede ser orientado a conexión o no orientado a conexión. Un socket se puede considerar como un punto final en una comunicación. Un socket cliente en un computador utiliza una dirección para llamar a u socket de servidor en otro computador. Una vez que han entrado en comunicación los sockets, los dos computadores pueden intercambiar datos.
	\end{itemize}

\item Paso de mensajes. Los procesos se comunican por medio de mensajes, que son un conjunto de bytes con un tipo asociado. Asociada a cada proceso existe una cola de mensajes, que funciona como buzón.

\item Memoria compartida. Es la forma más rápida de comunicación entre procesos. Se trata de un bloque de  memoria virtual compartido por múltiples procesos. Los procesos leen y escriben en la memoria compartida utilizan las mismas instrucciones de máquina que se utilizan para leer y escribir en otras partes de su espacio de memoria virutal.
\end{itemize}

En algunos libros no se considera la tubería como un tipo de comunicación en sí mismo, ya que quería dentro de alguno de los otros dos.

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=60mm]{tipos_com.png}
\end{figure}

\textbf{Concurrencia y paralelismo:}

Varios procesos pueden ejecutarse,
\begin{itemize}
\item en paralelo en un multiprocesador.

\item de forma concurrente en un uniprocesador.
\end{itemize}

No se debe confundir concurrencia con paralelismo, pues aunque la concurrencia da una impresión de paralelismo, realmente lo único que hace es un empleo muy eficiente del tiempo de ejecución del procesador, dando lugar a la sensación de ejecución de varios procesos simultáneamente, pero relamente en ningún momento el procesador tiene en ejecución dos procesos distintos en el mismo instante.

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{concurrenciavsparalelismo.png}
\end{figure}

Los procesos multihebra pueden ser ejecutados de forma paralela o concurrente en función de
\begin{itemize}
\item el número de procesadores

\item el modelo de hebras: usuario o núcleo.
\end{itemize}

Podrán aparecer "condiciones de carrera" si no manejamos cuidadosamente la concurrencia, lo que implica la necesidad de métodos de sincronización de procesos y hebras.

\textbf{Condiciones de carrera:} sucede cuando múltipres procesos o hilos leen y escriben datos de forma que el resultado final depende del orden de ejeucicón de las instrucciones en los múltiples procesos.\\

\textbf{Gestión de memoria.}

La memoria RAM es limitada. De aquí surge el problema de que los procesos no saben qué posición ocuparán en la RAM. La posición de los procesos en RAM es responsabilidad del compilador y del sistema operativo. La solución a este problema es la utilización de código relocalizable. Este código tiene la particularidad de que en vez de trabajar con direcciones físicas trabaja con direcciones relativas al código, es decir, en lugar de hacer un salto a la dirección 0xffff, se hace un salto a la dirección en la que está la instrucción actual-5. De esta forma ya no es necesario saber exactamente donde está cada cosa, sino que se buscará donde está la ejecución instrucción actual-5, cuya dirección puede variar entre ejecuciones (o incluso dentro de la misma ejecución). 

Otro problema que surge es que la necesidad de memoria de todos los procesos activos pueden ser mayores que la RAM. La solución es el uso de memoria virtual, la cual da al proceso la impresión de tener más memoria disponible de la que realmente tiene, y este diferencia entre la memoria real y la virtual se suple con la carga de páginas de memoria bajo demanda. De esta forma no se requiere que todo el proceso esté cargado en memoria, sino unas ciertas páginas concretas, y se cargan las que se necesitan según la demanda del programa.\\

\textbf{Memoria virtual:} Permite al programador direccionar memoria de forma razonable en cuanto a

\begin{itemize}
\item Cantidad: los procesoso creen disponer de toda la RAM.

\item Seguridad: los espacios de direcciones son independientes. Una misma dirección virtual en dos espacios de direcciones distintos puede ser mapeada en diferentes posiciones en la RAM.

\item El mapeado de porciones de memoria virtual en memoria física se hace de forma automática, liberando así al programador de esta tarea.
\end{itemize}

El funcionamiento eficiente de la memoria virtual requiere soporte hardware.\\

Con la memoria virtual las aplicaciones creen tener un espacio de direcciones plano. La memoria física se divide en prociones. Las regiones no necesitan mapearse de forma continua, a excepción de la E/S mapeada en memoria (controladores). (Para maś información ver la explicación de memoria virtual del tema 1).

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{mem_virtual.png}
\end{figure}

\textbf{Planificación/gestión de recursos}

\begin{itemize}
\item Equidad: normalmente, se desea que todos los procesos que compiten por un determinado recurso, se les conceda un acceso equitativo a dicho recurso. Esto es especialmente cierto para trabajos de la misma categoría, es decir, trabajos con demandas similares.

\item Tiempo de respuesta: el sistema operativo puede necesitar discriminar entre diferentes clases de trabajos con diferentes requisitos de servicio. El sistema operativo debe tomar las decisiones de asignación y planificación con el objetivo de satisfacer el conjunto total de requisitos. Además, debe tomar las decisiones de forma dinámica. 

\item Eficiencia: el sistema operativo debe intentar maximizar la proximidad, minimizar el tiempo de respuesta, y, en caso de sistemas de tiempo compartido, acomodar tantos usuarios como sea posible. Estos criterios entran en conflicto: encontrar un compromiso adecuado en una situación particular es un problema objeto de la investigación sobre sistemas operativos.
\end{itemize}

Diferencia entre políticas y mecanismos:
\begin{itemize}
\item Planificación $\Leftrightarrow$ apropiación/explusión

\item Paginación $\Leftrightarrow$ reemplazo.

\item Interacción $\Leftrightarrow$ comunicación.
\end{itemize}

\textbf{Gestión de E/S:}

Clasificación de dispositivos de E/S:
\begin{itemize}
\item Dispositivos de caracteres: aquellos que envían o reciben un flujo de carateres, sin sujetarse a una estructura de bloques. No se pueden utilizar direcciones ni tienen una operación de búsqueda. Ejemplos: puerto de serie, módem, ratón, ...

\item Dispositivos de bloques: aquellos que almacenan la información en bloques de tamaño fijo, cada uno con su propia dirección. Ejemplos: discos duros, tarjetas de red, ...
\end{itemize}

Papel de la gestión de dispositivos $\Rightarrow$ interfaz:
\begin{itemize}
\item Porporcionar una interfaz genérica, como en UNIX. En UNIX cada dispositivo de E/S está asociado con un fichero especial, que lo gestiona el sistema de ficheros y se lee y escribe de la misma manera que los ficheros de datos de usuario. Esto proporciona una interfaz bien definida y uniforme para los usuarios y los procesos. Para leer o escribir de un dispositivo, se realizan peticiones de lectura o escritura en el fichero especial asociado con el dispositivo.

\item Proporcionar una interfaz específica para cada tipo de dispositivo, como en Windows. Windows dispone de un gestor de E/S, que es responsable de todo el sistema de E/S del sistema operativo y proporciona una interfaz uniforme a la que todos los tipos de manejadores pueden llamar. 
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=50mm]{ES_windows.png}
\end{figure}

Componentes de un controlador de dispositivo (software):
\begin{itemize}
\item Código de inicialización

\item Llamada al sistema para responder a las peticiones de usuario

\item Manejador de interrupción para responder a las peticiones del controlador de dispositivo (hardware)
\end{itemize}

\textbf{Ficheros}

Implementación del almacenamiento persistente o a largo plazo. Las unidades almacenadas persistentemente son objetos como:
\begin{itemize}
\item Ficheros

\item Directorios
\end{itemize}

Tipos de ficheros:
\begin{itemize}
\item Tradicionales: gestionados a través de llamadas al sistema.

\item Mapeados en memoria: se gestionan igual pero se almacenan en la memoria principal.
\end{itemize}

\textbf{Interacción de los componentes del sistema}

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{interaccion_sistema.png}
\end{figure}

\textbf{Interfaz de programación de aplicaciones (API)}

Existen dos interfaces de programación para acceder a los servicios proporcionados por el núcleo del SO:
\begin{itemize}
\item Llamadas al sistema: interfaz directa con el núcleo.

\item API: interfaz indirecta escrita en algún lenguaje de alto nivel (funciones de biblioteca).
\end{itemize}

Las 3 APIs más conocidas son:
\begin{itemize}
\item Win32/Win64

\item POSIX: Portable Operating System Interface (UNIX)

\item Java
\end{itemize}

\textbf{Paso de parámetros:}

A menudo es necesaria más informació que la identificación de la llamada al sistema. El tipo y cantidad de información varia entre llamadas.

Métodos de paso de parámetros:
\begin{itemize}
\item Registros: método rápido pero de poca capacidad

\item Memoria: la aplicación agrupa los parámetros en un área de memoria y pasa la localización de dicha área mediante un registro.

\item Pila: los parámetros son apilados por la aplicación y desapilados por la llamada al sistema.
\end{itemize}

El empleo de memoria tiene la ventaja de no limitar el número ni el tamaño de los parámetros, pero es más lenta que los registros (velocidad+copia). La estrategia más flexible para el paso de parámetros es la pila.

\subsection{Llamadas al sistema}
\begin{itemize}
\item \textbf{Gestión de procesos}

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{llamadas_1.png}
\end{figure}
\newpage

\item \textbf{Gestión de ficheros:}

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=110mm]{llamadas_2.png}
\end{figure}

\item \textbf{Gestión de directorios}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=110mm]{llamadas_3.png}
\end{figure}
\newpage

\item \textbf{Otras llamadas al sistema}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=110mm]{llamadas_4.png}
\end{figure}

\item \textbf{Comparativa POSIX/Win32}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=110mm]{comparativa.png}
\end{figure}

\end{itemize}

\section{Tema 3: Historia de los Sistemas Operativos}
\subsection{Definición}
\textbf{Sistema operativo:} programa o conjunto de programas encargado de gestionar los recursos de la máquina y proveer servicios al resto de programas. Suele ejecutarse en modo privilegiado. Controla la ejecución de aplicaciones y programas y actúa como interfaz entre las aplicaciones y el hardware del computador. 

Suelen venir junto con multitud de otros programas, que sin forma parte del sistema operativo, resultan de suma utilidad: intérprete de órdenes, editor de texto, gestor de ficheros, navegador, ...

\subsection{Historia}
\subsubsection{Primera generación (1945-1955): Tubos de vacío y paneles}
Algunos de los primeros ordenadores digitales eran binarios, algunos usaban tubos de vacío, otros eran programables, pero todo eran muy primitivos y tardaban segundos en realizar incluso los cálculos más simples.\\

En esta generación un pequeño grupo de gente (normalmente ingenieros) diseñaba, construía, programaba, operaba y mantenía cada máquina (genios como Aiken, von Neuman o Mauchley). Toda la programación se realizaba en lenguaje máquina o incluso peor, cableando circuitos electricos conectando miles de cables a un clavijero para controlar las funciones básicas de la máquina. Por ese entonces los lenguajes de programación eran inexistentes y los sistemas operativos desconocidos.\\

Se utilizaban para resolver problemas matemáticos y cálculos numéricos, ales como cosenos y logaritmos o computación de trayectorias de artillería.

\subsubsection{Segunda generación (1955-1965): Transistores y sistemas por lotes}
La invención del transistor cambió radicalmente la situación. Los ordenadores se volvieron suficientemente confiables para ser manufacturados y vendidos a consumidores con la esperanza de que funcionen el suficiente tiempo para obtener la consecución algún trabajo útil. Se hace una separación entre diseñadores, constructores, operadores, programadores y personal de mantenimiento.\\

Estas máquinas se conocen actualmente como mainframes (IBM 1401, IBM 7094, la primera es una máquina para la escritura de cintas y la otra para el cálculo de operaciones). Para ejecutar una tarea el programador primero escribe el programa en papel (en FORTRAN o ensamblador), luego lo escribía en tarjetas, es decir, se programa en ensamblador o lenguajes de alto nivel.\\

Debido al alto coste del equipo se buscaron formas de reducir el tiempo desperdiciado. La solución fueron los sitemas por lotes. La idea era recolectar una bandeja de tareas, escribirlas en una cinta magnética, llevarlas a la máquina de cálculo que hace los cálculos y los escribe en otra cinta magnética, y imprimir los resultados. Surge así el procesamiento por lotes.\\

Los ordenadores de segunda generación se utilizaron principalmente para cálculos cinetíficos y de ingeniería, como resolver ecuaciones diferenciales parciales. Los sistemas operativos más típicos eran FMS (el Fortran Monitor System) y IBSYS, el sistema operativo de IBM para el 7094.

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{solotes.png}
\end{figure}

\subsubsection{Tercera generación (1965-1980): Circuitos integrados y multiprogramación}
A principios de los 60, la mayoría de fabricantes de ordenadores tomaron dos lineas de producto distintas e incompatibles. La primera era la orientada a palabras y ordenadores científicos de gran escala como el 7094, los cuales se utilizaron para cálculos numéricos en ciencia e ingeniería a nivel industrial.

La segunda orientada a caracteres, ordenadores comerciales, como el 1401, los cuales eran ampliamente utilizados por bancos y compañías de seguros, en la ordenación de cintas y la escritura.\\

Se empiezan a utilizar circuitos integrados, así se pudo proveer una mayor relación precio/rendimiento respecto a las máquinas de la segunda generación, las cuales se basaban en transistores individules (IBM 360, GE-645, DEC, PDP-1).\\

Como logro más destacables tenemos:
\begin{itemize}
\item Multiprogramación.

\item Spooling (Simultaneos Peripheral Operation On Line). Habilidad de leer trabajos de tarjetas al disco tan pronto se traen a la sala de computación. Así, cuando el trabajo en ejecución termine, el sistema operativo puede cargar un nuevo trabajo desde el disco en la partición vacía y ejecutarlo.

\item Tiempo compartido. Varicación de la multiprogramación, en la cual cada usuario tiene un terminal online.
\end{itemize}

Ejemplos: OS/360, CTSS, MULTICS, UNIX.

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=100mm]{multiprogramacion.png}
\end{figure}

\subsubsection{Cuarta generación (1980-hoy): Ordenador personal (era $\mu$)}
Con el desarrollo de circuitos LSI (Integración de Gran Escala) - chips con cientos de transistores por centímetro cuadrado de silicona - estalla la era el ordenador personal. 

Surgen arquitecturas de procesadores como los 8080, Z80, 80x86, Alpha, Ultrasparc, ARM.\\

Como logros destacables tenemos:
\begin{itemize}
\item GUI (Graphic User Interface).

\item SO de red. Los usuarios son conscientes de la existecia de múltiples ordenadores y pueden registrase en cada máquina remota y copiar archivos de una máquina a otra

\item SMP (Symmetric Multi-Processing).

\item SO distribuidos.
\end{itemize}

Ejemplos: UINX, CP/M, MS-DOS, Linux, MacOS, Windows.\\


\subsection{Estructura}
\textbf{Clasificación:}
\begin{itemize}
\item Estructura simple:
	\begin{itemize}
	\item Monolíticos. Son sistemas operativos en los cual el núcleo proporciona la mayoría de las funcionalidades propias del sistemas operativo, incluyendo la planificación, los sistemas de ficheros, las redes y otras funciones.
	
	\item Capas. Las funciones se organizan jerárquicamente y sólo hay interacción entre las capas adyacentes. Con el enfoque por capas, la mayor parte o todas las capas ejecutan en modo núcleo.
	
	\item Modulares
	\end{itemize}

\item Estructura cliente/servidor:
	\begin{itemize}
	\item Micronúcleo. Asigna unas pocas funciones esenciales al núcleo, incluyendo los espacios de almacenamiento, comunicación entre procesos y planificación básica.
	
	\item Exonúcleo.
	\end{itemize}
	
\item Máquina virtual.

\item Híbridos
\end{itemize}

\textbf{Tendencias:}
\begin{itemize}
\item Núcleos Extensibles

\item Multiservidores sobre un micronúcleo.

\item Núcleos híbridos.
\end{itemize}

\textbf{Monolítico:}

El Sistema operativo completos se ejecuta en modo protegido. Como consecuencia hay una protección nula entre los componentes del mismo, pues cualquier fallo puede afectar a cualquier parte del sistema operativo.\\

Ventajas:
\begin{itemize}
\item La capacidad de llamar a cualquier procedimiento que se quiera es muy eficiente.
\end{itemize}

Desventajas:
\begin{itemize}
\item La falta de protección implica una menor fiabilidad. Tener miles de procedimientos que pueden llamarse entre ellos sin restricción puede llevar a un sistema que es  dificil de entender. Además, un fallo en cualquiera de esos procedimientos tumbaría el sistema operativo entero. 

\item Mal manejo de la complejidad. Es más sentillo escribir 1000 programas de 1000 líneas que uno de 1000000
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=90mm]{monolitico.png}
\end{figure}

\textbf{Capas/Niveles:}

El Sistema Operativo completo se ejecuta en modo protegido. Hay una escasa división entre los componentes.\\

Ventajas:
\begin{itemize}
\item Es muy eficiente gracias a la economía de cambios de contexto.

\item La complejidad es menor que la de los sistemas operativos monolíticos.
\end{itemize}

Desventajas:
\begin{itemize}
\item La falta de protección implica una menor fiabilidad.

\item Menos flexible que un sistema operativo monolítico.

\item Es difícil subdividir adecuadamente las capas.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{capasniveles.png}
\end{figure}

\textbf{Modular:}

El Sistema Operativo se ejecuta en modo protegido. Una vez más esto implica una escasa protección entre los componentes.\\

Ventajas:
\begin{itemize}
\item De nuevo la econocomías de cambios de contexto lo hace eficiente.

\item Tiene una menos complejidad.
\end{itemize}

Desventajas:
\begin{itemize}
\item La falta de protección implica una menor fiabilidad.

\item Es menos flexible que un sistema operativo monolítico.

\item Es difícil elegir que colocar en el núcleo y que en los módulos.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=90mm]{modular.png}
\end{figure}
\newpage

\textbf{Micronúcleo/Microkernel}

Una mínima parte del Sistema Operativo se ejecuta en modo protegido. \\

Ventajas:
\begin{itemize}
\item La perfecta protección entre componente nos da una mayor fiabilidad

\item Manejo de la complejidad.

\item Facilidad de programación
\end{itemize}

Desventajas:
\begin{itemize}
\item Debido a la sobrecarga en las comunicaciones hay una menor eficiencia.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{microkernel.png}
\end{figure}

\newpage

\textbf{Exonúcleo:}

Apenas existe el sistema operativo, sólo un gestor de recursos. En este tipo de sistema operativo dejamos que el software accedad directamente al hardware.\\

Ventajas:
\begin{itemize}
\item Perfecta protección entre componentes, lo cual da lugar a una alta fiabilidad.

\item El acceso directo al hardware nos da lugar a una máxima eficiencia.
\end{itemize}

Desventajas:
\begin{itemize}
\item Pobre reutilización del código.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=90mm]{exonucleo.png}
\end{figure}

\newpage

\textbf{Máquina virtual:}

Se trata de copias virtuales de la máquina rel:
\begin{itemize}
\item SW: Bochs, Qemu, VMWare, Xen.

\item HW: VMWare, Xen
\end{itemize}

Ventajas:
\begin{itemize}
\item Perfecta protección entre componentes, lo que garantiza una alta fiabilidad.

\item Mejor aprovechamiento del hardware.

\item Máxima reutilización del código.
\end{itemize}

Desventajas:
\begin{itemize}
\item La simulación del hardware real puede ser costosa, dando lugar a una baja eficiencia.
\end{itemize}

Esta opción es un éxito gracias a mejoras en el HW.

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=90mm]{maquinavirtual.png}
\end{figure}

\newpage
\textbf{Híbrida}

\begin{itemize}
\item La mezcla más frecuente es la combinación de micronúcleo y monolítico.

\item Ventaja: ganamos velocidad respecto al micronúcleo.

\item Desventaja: perdemos protección entre componentes.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{hibrida.png}
\end{figure}

\newpage
\subsection{Ejemplos}
\textbf{MS-DOS}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{MSDOS.png}
\end{figure}

\newpage

\textbf{Windows 2000}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{WINDOWS2000.png}
\end{figure}

\newpage

\textbf{Linux}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{linux.png}
\end{figure}

\newpage

\textbf{Mach}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{mach.png}
\end{figure}

\textbf{MacOS X}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=105mm]{MacOSX.png}
\end{figure}

\newpage

\textbf{QNX}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{qnx.png}
\end{figure}

\newpage
\subsection{Comparativa}
\subsubsection{Coste estructural de una llamada al sistema: caso monolítico}
\textbf{1 llamada al sistema:}
\begin{enumerate}
\item Entrada al núcleo.

\item Cambio al espacio de direccionies del núcleo.

\item Salida del núcleo.
\end{enumerate}

\textbf{1 llamada a procedimiento:} llamada y retorno en el interior del espacio de direcciones del núcleo y pudiendo compartir información.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=100mm]{llamada_sistema.png}
\end{figure}
\newpage

\subsubsection{Coste estructural de una llamada al sistema: caso micronúcleo}
\textbf{4 llamadas al sistema:}
\begin{enumerate}
\item Entrada al micronúcleo.

\item Cambio al espacio de direcciones del micronúcleo.

\item Transferencia del mensaje.

\item Recuperar el espacio de direcciones original.

\item Salida del micronúcleo.
\end{enumerate}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{llamada_kernel.png}
\end{figure}

\newpage

\subsubsection{Coste estructural: multiservidor}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{multisevidor.png}
\end{figure}

\section{Tema 4: Procesos}
\subsection{Definición}
\textbf{Proceso (definiciones):}
\begin{itemize}
\item Programa en ejecución
\item Entorno de protección
\item Algo dinámico
\end{itemize}

\textbf{Componentes básicos:}
\begin{itemize}
\item Hebras/hilos de ejecución
\item Espacio de direcciones.
\end{itemize}

\textbf{La tarea fundamental de un SO es la gestión de procesos:}
\begin{itemize}
\item Creación
\item Planificación
\item Comunicación
\item Finalización
\end{itemize}

Un programa es
\begin{itemize}
\item Una lista de instrucciones
\item Algo estático
\item Varios procesos pueden ejecutar un mismo programa
\end{itemize}

Puede lanzar, o ser lanzado por, otros procesos.\\

\textbf{Modelo de procesamiento:} 

Todo el software se organiza en forma de procesos, donde
\begin{equation*}
proceso=programa+entorno\:(procesador+memoria)
\end{equation*}

\textbf{Objetivos:}
\begin{itemize}
\item Multiprogramación: maximizar el uso del procesador, para mantener a este continuamente ocupado y así maximizar el rendimiento.

\item Tiempo Compartido: cada proceso cree tener el sistema por completo. Cambian entre ellos con frecuencia en los momentos precisos para que así todos accedan a los recursos de forma equitativa.
\end{itemize}

\textbf{Clasificación en función del coste del cambio de proceso:}
\begin{itemize}
\item Procesamiento pesado: procesos UNIX
	\begin{itemize}
	\item Hebra de actividad y espacio de direcciones unificado
	
	\item El cambio de proceso implica dos cambios en el espacio de direcciones
	
	\begin{equation*}
	ED_x\rightarrow ED_{SO}\rightarrow ED_y
	\end{equation*}
	\end{itemize}

\item Procesamiento ligero: hebras tipo núcleo.
	\begin{itemize}
	\item Hebra de actividad y espacio de direcciones desacoplados.
	
	\item El cambio de hebra implica uno o dos cambios de espacio de direcciones en función de si las hebras comparten o no.
	
	\begin{equation*}
	ED_x\rightarrow ED_{SO}\rightarrow ED_y
	\end{equation*}
	\end{itemize}
	
\item Procesamiento superligero/pluma: hebras tipo usuario.
	\begin{itemize}
	\item Hebras de actividad y espacio de direcciones unificados.
	
	\item El cambio de hebra no implica cambio de espacio de direcciones.
	
	\begin{equation*}
	ED_x\rightarrow ED_y
	\end{equation*}
	\end{itemize}
\end{itemize}

\subsection{Control}
\textbf{Estructuras de control del SO}
Para gestionar procesos y recursos el SO debe disponer de información sobre estos. Para ello el SO mantiene tablas sobre cada elemento que gestiona:
\begin{itemize}
\item Tablas de memoria: principal y secundaria, protección, traducción. Se usan para mantener un registro tanto de la memoria principal (real) como de la secundaria (virtual). Parte de la memoria principal está reservada para el uso del SO, mientras que el resto está disponible para el uso de los procesos. Las tablas de memoria pueden contener la siguiente información:
	\begin{itemize}
	\item Las reservas de memoria principal por parte de los procesos
	
	\item Las reservas de memoria secundaria por parte de los procesos
	
	\item Todos los atributos de protección que restringe el uso de la memoria principal y virtual, de forma que los procesos puedan acceder a ciertas áreas de memoria compartida.
	
	\item La informacion necesaria para manejar la memoria virtual.
	\end{itemize}

\item Tablas de E/S: dispositivos y canales, estado de las operaciones. Información para gestionar los dispositivos de E/S y los canales del computador.

\item Tablas de ficheros: existencia, atributos, localización,... Información sobre la existencia de ficheras, su posición en almacenamiento secundario, su estado actual y otros atributos.

\item Tablas de procesos: localización y atributos. 
\end{itemize}

Estas tablas no suelen estar separadas, sino entrelazadas. Normalmente estas se inicializan al arrancar el sistema.\\

\textbf{Representación física de un proceso:}
\begin{itemize}
\item Imagen del proceso:
	\begin{itemize}
	\item Programa a ejecutar.
	
	\item Espacio de direcciones disponible para código, datos, pila, ...
	\end{itemize}

\item Bloque de Control del Proceso (PCB) o descriptor de proceso:
	\begin{itemize}
	\item Atributos para la gestión del proceso por parte del SO.
	
	\item Es la estructura de datos más importante del SO.
	\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{pcb1.png}
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{pcb2.png}
\end{figure}
\end{itemize}

\textbf{Atributos de un proceso:}
\begin{itemize}
\item Identificación del proceso: identificadores del proceso, porceso padre, usuario.

\item Estado del procesador: registros de propósito general, de estado y control (PSW, \textit{program status word}), puntero de pila.

\item Información de control del proceso: estado, planificación, estructuración, comunicación y sincronización, privilegios, gestión de memroia, control de recursos y utilización.
\end{itemize}

\textbf{Control de procesos}
\begin{itemize}
\item Modos de ejecución. La mayor parte de los procesadores proporcionan al menos dos modos de ejecución:
	\begin{itemize}
	\item Modo usuario: permite la ejecución de instrucciones que no afectan a otros procesos.
	
	\item Modo núcleo: permite la ejecución de cualquier instrucción.
	\end{itemize}

Existen otros modos intermedio que solían usarse en controladores de dispositivos y bibliotecas de lenguajes. Un bit en la palabra de estado indica en que modo se está ejecutando el procesador.
	\begin{itemize}
	\item El bit puede consultarse como el resto de la palabra de estado.
	
	\item Se modifica cuando se produce una llamada al sistema o una interrupción.	
	
	\item Al retornar de una llamada al sistema o de una interrupción se devuelve el valor original de dicho bit desde la pila.
	\end{itemize}

\item Creación de procesos.

\item Finalización de procesos.

\item Jerarquía de procesos.

\item Cambio de procesos.

\item Ejecución del sistema operativo.
\end{itemize}

\newpage
\textbf{Funciones típica del núcleo de un SO:}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{kernel.png}
\end{figure}

\textbf{Creación de procesos}.

Salvo sistemas extremadamente simples, todo SO tiene mecanismos para crear nuevos procesos. Posibles causas de la creación de un procesos: 
\begin{enumerate}
\item Inicialización del sistema:
	\begin{itemize}
	\item Interactivos / no interactivos
	
	\item Primer /segundo plano
	\end{itemize}
	
\item Llamada al sistema para crear un proceso.
	\begin{itemize}
	\item fork() + exec()/CreateProcess()
	\end{itemize}
	
\item Petición de usuario
	\begin{itemize}
	\item Lanzamiento de una nueva aplicación desde el interfaz de usuario
	\end{itemize}
	
\item Inicio de un proceso por lotes
	\begin{itemize}
	\item Sistemas de colas de trabajos en servidores
	\end{itemize}
\end{enumerate}

Pasos en la creación de un proceso:
\begin{enumerate}
\item Asignar un identificador de proceso único. Se añade una nueva entrada a la tabla primaria de procesos, que contiene una entrada por proceso.

\item Reservar espacio para el proceso. El SO debe conocer cuánta memoria se requiere para el espacio de direcciones privado (programas y datos) y para la pila de usuario. 
	\begin{itemize}
	\item Estructuras de datos del SO (PCB).
	
	\item Imagen del proceso.
	\end{itemize}
	
\item Inicialización del bloque de control del proceso (PCB). Habitualmente se inicializa con la mayoría de entradas a 0, excepto el contador de programa (fijado en el puntero entrada del programa) y los punteros de pila de sistema (fijados para definir los límites de la pila del proceso). La información de control de procesos se inicializa en base a los valores por omisión, considerando también los atributos que han sido solicitados para este proceso. La prioridad se puede fijar, por defecto, a la maś baja, a menos que una solicitud explícita la eleve a una prioridad mayor. Inicialmente, el proceso no debe poseer ningún recurso a menos que exista una indicación explícita de ello o haya sido heredado del padre.
	\begin{itemize}
	\item ppid, estado, ip, sp, prioridad, E/S, ...
	\end{itemize}
	
\item Establecimiento de enlaces adecuados:
	\begin{itemize}
	\item Cola de trabajos
	\end{itemize}
	
\item Creación o expansión de otras estructuras de datos:
	\begin{itemize}
	\item Auditoría, monitorización, análisis de rendimiento, ...
	\end{itemize}
\end{enumerate}

\textbf{Finalización de procesos:}

Los procesos se crean, se ejecutan y se finalizan. Las causas de finalización de un proceso pueden ser:
\begin{itemize}
\item Voluntarias:
	\begin{itemize}
	\item Terminación normal: la mayoría de los procesos realizan su trabajo y devuelven el control al SO mediante la llamada al sistema exit() / ExitProcess().
	
	\item Terminación por error: falta argumento, ...
	\end{itemize}

\item Involuntarias:
	\begin{itemize}
	\item Error fatal: instrucción privilegiada, excepción de coma flotante, violación de segmento, ...
	
	\item Terminado por otro proceso: mediante la llamada al sistema kill() / TerminateProcess()
	\end{itemize}
\end{itemize}

Una vez finalizado es necesario, auditoría/contabilidad del uso de recursos y recuperar/reciclar recursos. \\

\textbf{Jerarquía de procesos:}\\

\textbf{UNIX:}
\begin{itemize}
\item El uso de \textbf{fork()} crea una relación jerárquica entre procesos.

\item \textbf{init/systemd} suele ser el primer proceso del sistema.

\item La relación no se puede modificar.

\item Si un proceso padre finaliza antes alguno de sus hijos estos pasan a depender del ancestro previo.

\item Útil para llevar a cabo operaciones sobre grupos de procesos.
\end{itemize}

\textbf{Windows:}
\begin{itemize}
\item \textbf{CreateProcess()} no establece realción entre procesos.
	\begin{itemize}
	\item Se crea un objeto que permite controlar al nuevo proceso.
	
	\item Se puede traspasar la propiedad de este objeto.
	\end{itemize}
\end{itemize}

\textbf{Cambio de proceso:}

Se trata de una operació costosa. Por ejemplo, en Linux 2.4.21 un cambio de proceso requiere 5.4 $\mu$s o 13200 ciclos en un Intel Pentium IV a 2.4GHz. Los eventos que pueden provocar un cambio de proceso son:
\begin{itemize}
\item Interrupción.
	\begin{itemize}
	\item Interrupción del reloj. El SO determina si el proceso en ejecución ha excedido o no la unidad máxima de tiempo de ejecución, denominada rodaja de tiempo (time slice).
	
	\item Finalización de operación de E/S o DMA. El SO determina qué acción de E/S ha ocurrido. Si la acción de E/S constituye un evento por el cuál están esperando uno o más procesos, el sistema operativo mueve todos los procesos correspondientes al estado de Listos. El SO puede decidir si reanuda la ejecución del procesos actualmente en estado Ejecutando o si lo expulsa para proceder con la ejecución de un proceso Listo de mayor prioridad.
	\end{itemize}

\item Excepción: fallo de página/segmento, llamada al sistema (int/syscall), operación de E/S, ...
\end{itemize}

Cambio de modo: cambio del modo de privilegio ocn el que se ejecuta el procesador. Es una operación sencilla y poco costosa.\\

Cambio de contexto es ambiguo.\\

\textbf{Pasos a seguir para realizar el cambio de proceso:}
\begin{enumerate}
\item Salvar el estado del procesador, incluyendo el contador de programa y otros registros.

\item Actualizar el bloque de control del proceso que está actualmetne en el estado de Ejecutando. Esto incluye cambiar el estado del proceso a uno de los otros estados. También se tienen que actualizar otros campos importantes, incluyendo la razón por la cual el proceso ha dejado el estado de Ejecutando y demás información de auditoría.

\item Mover el bloque de control de proceso a la cola apropiada.

\item Selección de un nuevo proceso a ejectuar,

\item Actualizar el bloque de control del proceso elegido. Esto incluye pasarlo al estado Ejecutando.

\item Actualizar las estructuras de datos de gestión de memoria. Estos se puede necesitar, dependiendo de cómo se haga la traducción de direcciónes.

\item Restaurar el estado del procesador al que tenía en el mmoemnto en el que el proceso seleccionado salió del estado Ejecutando por última vez, leyendo los valores anteriores de contador de programa y registros.
\end{enumerate}

\textbf{UNIX:fork()+exec()+wait()+exit()}
\begin{itemize}
\item fork(): crea un nuevo proceso.

\item exec(): cambia la imagen de un proceso

\item wait(): permite al padre esperar al hijo

\item exit(): finaliza el proceso
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{fork.png}
\end{figure}

\subsection{Ejecución del Sistema Operativo}
\subsubsection{Núcleo independiente}
Es el método más antiguo. El SO no es un proceso (aunque se comporte como uno). Además, dispone de áreas de memoria y pila propias. El sistema operativo puede realizar todas las funciones que necesite y restaurar el contexto del proceso interrumpido, que hace que se retome la ejecución del proceso de usuario afectado. De forma alternativa, el sistema operativo puede realizar la salvaguarda del contexto y la activación de otro proceso diferente. Si esto ocurre o no depende de la causa de la interrupción y de las circunstancias puntales en el momento. 

El concepto de proceso es aplicable sólo a programas de usuario. El código del SO se ejecuta como una entidad independiente que requiere un modo privilegiado de ejecución.\\

El inconveniente es que cada evento cuesta un cambio de proceso y modo.

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{nucleo_independiente.png}
\end{figure}

\subsubsection{Ejecución dentro de los procesos de usuario}
El SO parece un conjunto de subrutinas que el proceso puede invocar desde su espacio de direcciones. A la imagen de cada proceso se une la del SO. Cuando oucrre una interrupción, \textit{trap} o llamada al sistema, el procesador se pone en modo núcleo y el control se pasa al sistema operativo. Para este fin, el contexto se salva y se cambia de modo a una rutina del sistema operativo. Sin embargo, la ejecución continúa dentro del proceso de usuario actual. De esta forma, no se realiza un cambio de proceso, sino un cambio de modo dentro del mismo proceso.\\

Ventaja: cada evento cuesta sólo un cambio de modo.

Inconveniente: restamos espacio al proceso de usuario.
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=80mm]{dentro_so.png}
\end{figure}

\subsubsection{Sistemas operativos basados en procesos}
El SO se implementa como una colección de procesos. Debe haber una pequeña cantidad de código para intercambio de procesos que se ejecuta fuera de todos los procesos.

Ventajas: 
\begin{itemize}
\item Modularidad y facilidad de programación

\item Teórica mejora de rendimiento en sistemas multiprocesador.
\end{itemize}

Inconvenientes: un evento puede costar varios cambios de proceso y modo.

\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{procesos_so.png}
\end{figure}

\textbf{Traza de un proceso.}

Comportamiento de un proceso = lista de instrucciones que ejecuta, a la que denominaremos traza. 

\textbf{Activador (dispatcher):} programa encargado de cambiar entre los PCBs de los procesos para ejecutar un proceso u otro.\\

\textbf{Cola de procesos:}
\begin{itemize}
\item Creación de un proceso = crear PCB + cargar imagen

\item Lista de procesos = lista de PCBs.

\item Planificador ("\textit{scheduler}"):
	\begin{itemize}
	\item Parte del SO que escoge el siguiente proceso a ejecutar.
	
	\item Gestor de las colas de planificación.
	\end{itemize}

\item Activador ("\textit{dispatcher}"): parte del planificador que realiza un intercambio de procesos

\item Ejecución = encolar + activar.
\end{itemize}

\textbf{Modelo de 2 estados}

Estados:
\begin{itemize}
\item Ejecutando: proceso en ejecución

\item No ejecutando: proceso que no se está ejecutando.
\end{itemize}

Transiciones:
\begin{itemize}
\item Ejecutando $\rightarrow$ no ejecutando: evento o temporización

\item No ejecutando $\rightarrow$ ejecutando: temporización o fin de evento.
\end{itemize}

Inconvenientes:
\begin{itemize}
\item No permite discriminar fácilmente la razón por la que un proceso no se encuentra en ejecución.

\item Solución: subdividir el estado "no ejecutando" para reflejar el motivo.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{dos_estados.png}
\end{figure}

\textbf{Modelo de 5 estados}

Estados:
\begin{itemize}
\item Nuevo: el proceso ha sido creado

\item Preparado: proceso a la espera de que se le asigne un procesador.

\item Ejecutando: proceso actualmente en ejecución.

\item Bloqueado: proceso que no puede continuar hasta que finalice un evento.

\item Finalizado: proceso finalizado.
\end{itemize}

Transiciones:
\begin{itemize}
\item Nuevo $\rightarrow$ preparado: se admite un nuevo proceso en el sistema.

\item Preparado $\rightarrow$ ejecutando: el planificador selecciona el proceso para su ejecución.

\item Preparado $\rightarrow$ finalizado: padre termina hijo.

\item Ejecutando $\rightarrow$ finalizado: proceso finalizado.

\item Ejecutando $\rightarrow$ preparado: tiempo de procesador agotado.

\item Ejecutando $\rightarrow$ bloqueado: se produce un evento.

\item Bloqueado $\rightarrow$ preparado: finalización de evento.

\item Bloqueado $\rightarrow$ finalizado: padre termina hijo.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=90mm]{cinco_estados.png}
\end{figure}

\textbf{Modelo de +5 estados}

Añaden un nuevo estado, el estado suspendido. El objetivo de la multiprogramación es aprovechar al máximo el procesador por la lentitud de la E/S. Esto no resuelve el problema del modelo de 5 estados.
\begin{itemize}
\item Causa: diferencia de velocidad entre CPU y E/S.

\item Todos los procesos podrían llegar a estar bloqueados en espera de finalización de un evento.

\item Solución: añadir más procesos.

\item Problema: falta de memoria.
\end{itemize}

Se trata de un círculo vicioso difícil de romper:
\begin{itemize}
\item Solución cara: añadir maś memoria

\item Solución barata: memoria de intercambio ("\textit{swap}")
\end{itemize}

Intercambio ("\textit{swapping}"): proceso de expulsión de un proceso de memoria principal a secundaria y viceversa. Se agraba el problema, pues el intercambio requiere E/S.\\

\textbf{Modelos de 6 estados}
\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{6_estados.png}
\end{figure}

\newpage
\textbf{Modelo de 7 estados}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{7_estados.png}
\end{figure}

Motivación: el reactivar un proceso sólo para descubrir que sigue bloqueado es muy costoso.\\

Nuevos estados:
\begin{itemize}
\item Suspendido (bloqueado): proceso en área de intercambio y esperando un evento.

\item Suspendido (preparado): proceso en área de intercambio y a la espera de espacio en memoria principal.
\end{itemize}

Nuevas transiciones:
\begin{itemize}
\item Bloqueado $\rightarrow$ suspendido (bloqueado): no hay procesos preparados o estos consumen demasiada memoria.

\item Suspendido (bloqueado)$\rightarrow$ suspendido (preparado): sucede el evento por el que estaba bloqeuado.

\item Suspendido (preparado)$\rightarrow$ preparado: no quedan procesos preparados o tiene mayor prioridad que los preparados.

\item Preparado $\rightarrow$ suspendido (preparado): liberar memoria o dejar sitio para un proceso bloqueado de mayor prioridad.

\item Nuevo $\rightarrow$ suspendido (preparado): control de carga del sistema.

\item Suspendido (bloqueado) $\rightarrow $ bloqueado: queda memoria libre o proceso de alta prioridad.

\item Ejecutando $\rightarrow$ suspendido (preparado): un proceso agota su tiempo y hay que liberar memoria para un proceso suspendido de mayor prioridad.

\item X $\rightarrow$ finalizado: un proceso elimina a otro.
\end{itemize}

\newpage
\textbf{Diagrama de transiciones entre estados en UNIX}
\begin{figure}[h]
\centering
\includegraphics[scale=1, width=\textwidth]{diagrama_transicioens.png}
\end{figure}

\textbf{Planificación}

Los procesos pueden cambiar varias veces de cola de planificación a lo largo de su vida. La parte del SO encargada de realizar esos cambios es el planificador.\\

Tipos de planificadores:
\begin{itemize}
\item Corto plazo: slecciona entre los procesos preparados para ejecutar.
	\begin{itemize}
	\item Ejecución muy frecuentemente, ej: cada 10,...,100ms.
	\end{itemize}
	
\item Medio plazo: decide que procesos pasar al área de intercambio y así controla el grado de multiprogramación.

\item Largo plazo: selecciona que procesos poner en ejecución, ej: sistema por lotes.
	\begin{itemize}
	\item Ejecución en función de la carga del sistema, cada varios minutos o cuando finaliza un proceso.
	\end{itemize}
\end{itemize}

\textbf{Comunicación entre procesos}

Los procesos pueden ser:
\begin{itemize}
\item Independientes: no afecta ni es afectado por otros procesos (no comparten datos).

\item Cooperatnes: puede afectar y ser afectados por otros procesos (si comparten datos).
\end{itemize}

El SO debe proporcionar métdos para crear, comunicar y terminar procesos. Los motivos para cooperar son:
\begin{itemize}
\item Compartir información: capacidad de acceso y economía de recursos.

\item Acelerar los cálculos: realizar las tareas más rápidamente.

\item Modularidad: facilidad de creación de programas.

\item Conveniencia: multitarea
\end{itemize}

Métodos d ecomunicación (ya explicado):
\begin{itemize}
\item Memoria compartida.
	\begin{itemize}
	\item Los procesos comparten un área de memoria
	
	\item La comunicación es responsabilidad de los procesos.
	\end{itemize}

\item Paso de mensajes.
	\begin{itemize}
	\item Los procesos intercambian mensajes.
	
	\item Comunicación responsabilidad del sistema operativo.
	\end{itemize}
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[scale=1,width=\textwidth]{comunicacion.png}
\end{figure}



\end{document}
